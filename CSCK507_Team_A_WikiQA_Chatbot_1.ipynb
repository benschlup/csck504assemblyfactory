{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCK507_Team_A_WikiQA_Chatbot_1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/benschlup/csck507_team_a/blob/main/CSCK507_Team_A_ChatBot_THREE.ipynb",
      "authorship_tag": "ABX9TyOz+IRj/txgSVPnjM/7KAsM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschlup/csck504assemblyfactory/blob/main/CSCK507_Team_A_WikiQA_Chatbot_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **CSCK507 Natural Language Processing, March-May 2022: End-of-Module Assignment**\n",
        "# **Generative Chatbot**\n",
        "---\n",
        "#### Team A\n",
        "Muhammad Ali (Student ID )  \n",
        "Benjamin Schlup (Student ID 200050007)  \n",
        "Chinedu Abonyi (Student ID )  \n",
        "Victor Armenta-Valdes (Student ID )\n",
        "\n",
        "---\n",
        "# **Solution 1: LSTM without Attention Layer**\n",
        "---"
      ],
      "metadata": {
        "id": "dXeItkpo51bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset being used: https://www.microsoft.com/en-us/download/details.aspx?id=52419  \n",
        "Paper on dataset: https://aclanthology.org/D15-1237/  \n",
        "Solution inspired by https://medium.com/swlh/how-to-design-seq2seq-chatbot-using-keras-framework-ae86d950e91d  \n",
        "\n",
        "Additional interesting materials to review, and potentially reference:\n",
        "Khin, N.N., Soe, K.M., 2020. Question Answering based University Chatbot using Sequence to Sequence Model, in: .. doi:10.1109/o-cocosda50338.2020.9295021\n",
        "\n"
      ],
      "metadata": {
        "id": "kv0kmUiLmJSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Backlog:\n",
        "* Strip whitespace at beginning and end of questions and sentences\n",
        "* Check if lemmatizing on question side improves performance\n",
        "* Check if word embedding (e.g. using Word2Vec or GloVe) improves performance (beware of out-of-vocab)\n",
        "---"
      ],
      "metadata": {
        "id": "AHuZjEDChQ_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration"
      ],
      "metadata": {
        "id": "subk2_v1tjeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset includes invalid answers (labelled 0) and some questions \n",
        "# even have no valid answer at all: Switches allow test runs excluding invalid\n",
        "# answers.\n",
        "# Note that the assignment says that answers must be provided by the chatbot: \n",
        "# there is no mention that answers must be correct!\n",
        "train_with_invalid_answers = True\n",
        "validate_with_invalid_answers = True\n",
        "test_questions_without_valid_answers = True\n",
        "\n",
        "# The dataset contains questions with multiple valid answers\n",
        "train_with_duplicate_questions = True\n",
        "validate_with_duplicate_questions = True\n",
        "test_with_duplicate_questions = True\n",
        "\n",
        "# Configure the tokenizer\n",
        "vocab_size_limit = 6000 + 1 # set this to None if all tokens from training shall be included (add one to number of tokens)\n",
        "vocab_include_val = False   # set this to True if tokens from validation set shall be included in vocabulary\n",
        "vocab_include_test = False  # set this to True if tokens from test set shall be included in vocabulary\n",
        "oov_token = 1               # set this to None if out-of-vocabulary tokens should be removed from sequences\n",
        "remove_oov_sentences = True # set this to True if any sentences containing out-of-vocabulary tokens should be removed from training, validation, test dataset\n",
        "\n",
        "# Limit sentence lengths // not yet implemented\n",
        "max_question_tokens = 20    # set this to None if no limit on question length\n",
        "max_answer_tokens = 50      # set this to None if no limit on answer length"
      ],
      "metadata": {
        "id": "_hFMwuk8td8V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Fq0L8soItfbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import codecs\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import urllib.request\n",
        "import yaml\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#from gensim.models import Word2Vec\n",
        "\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ],
      "metadata": {
        "id": "CmdlY3dO1O_S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the GPU is visible to our runtime\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "metadata": {
        "id": "B9cNSuwm07wi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU we have in place\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ijf1uMKAXnbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebd7d3f-81ab-4b7b-9be8-eb724d113b6c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 11 17:18:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    40W / 250W |   2639MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data: If link does not work any longer, access file manually from here: https://www.microsoft.com/en-us/download/details.aspx?id=52419\n",
        "urllib.request.urlretrieve(\"https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\", \"WikiQACorpus.zip\")"
      ],
      "metadata": {
        "id": "mYkrBnyV1L-E",
        "outputId": "e94f31a2-b06c-4b45-a85d-3a75c7f4af66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('WikiQACorpus.zip', <http.client.HTTPMessage at 0x7f6f246dae90>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files\n",
        "with zipfile.ZipFile('WikiQACorpus.zip', 'r') as zipfile:\n",
        "   zipfile.extractall()"
      ],
      "metadata": {
        "id": "d09_-PN51ois"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import questions and answers: training, validation and test datasets\n",
        "train_df = pd.read_csv( f'./WikiQACorpus/WikiQA-train.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "val_df = pd.read_csv( f'./WikiQACorpus/WikiQA-dev.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv( f'./WikiQACorpus/WikiQA-test.tsv', sep='\\t', encoding='ISO-8859-1')       "
      ],
      "metadata": {
        "id": "e_tpDQAUEiKK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality checks and exploratory data analysis removed: dataset has proven clean\n",
        "# Print gross volumes:\n",
        "print(f'Gross training dataset size: {len(train_df)}')\n",
        "print(f'Gross validation dataset size: {len(val_df)}')\n",
        "print(f'Gross test dataset size: {len(test_df)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPMMJHDhvRsN",
        "outputId": "c69c9548-bfb9-4d8d-d153-7d714370ae8c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gross training dataset size: 20347\n",
            "Gross validation dataset size: 2733\n",
            "Gross test dataset size: 6116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove q/a pairs depending on configuration of the notebook\n",
        "if not train_with_invalid_answers:\n",
        "    train_df = train_df[train_df['Label'] == 1]\n",
        "if not validate_with_invalid_answers:\n",
        "    val_df = val_df[val_df['Label'] == 1]\n",
        "if not test_questions_without_valid_answers:\n",
        "    test_df = test_df[test_df['Label'] == 1]"
      ],
      "metadata": {
        "id": "7kJkWGVMs5kJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate questions in case configured to do so\n",
        "if not train_with_duplicate_questions:\n",
        "    train_df.drop_duplicates(subset=['Question'], inplace=True)\n",
        "if not validate_with_duplicate_questions:\n",
        "    validate_df.drop_duplicates(subset=['Question'], inplace=True)\n",
        "if not test_with_duplicate_questions:\n",
        "    test_df.drop_duplicates(subset=['Question'], inplace=True)"
      ],
      "metadata": {
        "id": "6hf9fo1r0PdJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive normalized questions and answers\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df.loc[:,'norm_question'] = [ re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", q).lower() for q in df['Question'] ]\n",
        "    df.loc[:,'norm_answer'] = [ '_START_ '+re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", s).lower()+' _STOP_' for s in df['Sentence']]"
      ],
      "metadata": {
        "id": "QQ1553hGYQL2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation:\n",
        "# Tokenization:\n",
        "# Reconsider adding digits to filter later, as encoding of numbers may create excessive vocabulary\n",
        "# Also check reference on handling numbers in NLP: https://arxiv.org/abs/2103.13136\n",
        "# Note that I do not yet train the tokenizer on validation and test datasets - should be challenged. \n",
        "# my be added to Tokenizer filters=target_regex = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\''\n",
        "\n",
        "if remove_oov_sentences:\n",
        "    oov_token = None\n",
        "tokenizer = Tokenizer(num_words=vocab_size_limit, oov_token=oov_token)\n",
        "\n",
        "tokenizer.fit_on_texts(train_df['norm_question'] + train_df['norm_answer'])\n",
        "if vocab_include_val:\n",
        "    tokenizer.fit_on_texts(val_df['norm_question'] + val_df['norm_answer'])\n",
        "if vocab_include_test:\n",
        "    tokenizer.fit_on_texts(test_df['norm_question'] + test_df['norm_answer'])\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "if vocab_size_limit is not None:\n",
        "    vocab_size = min([vocab_size, vocab_size_limit])\n",
        "print(f'Vocabulary size based on training dataset: {vocab_size}')\n",
        "\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df['tokenized_question'] = tokenizer.texts_to_sequences(df['norm_question'])\n",
        "    df['tokenized_answer'] = tokenizer.texts_to_sequences(df['norm_answer'])\n",
        "    df['question_tokens'] = [ len(x.split()) for x in df['norm_question'] ]\n",
        "    df['answer_tokens'] = [ len(x.split()) for x in df['norm_answer'] ]\n",
        "    if remove_oov_sentences:\n",
        "        df.drop(df[df['question_tokens']!=df['tokenized_question'].str.len()].index, inplace=True)\n",
        "        df.drop(df[df['answer_tokens']!=df['tokenized_answer'].str.len()].index, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZedlpHo6-62P",
        "outputId": "677a53df-20ca-410a-ec61-bd1743a28ea9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size based on training dataset: 6001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print net volumes\n",
        "print(f'Net training dataset size: {len(train_df)}')\n",
        "print(f'Net validation dataset size: {len(val_df)}')\n",
        "print(f'Net test dataset size: {len(test_df)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d6dbac-d4be-4107-aa17-143f717a838e",
        "id": "LuYn2ANsxSAm"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net training dataset size: 2181\n",
            "Net validation dataset size: 108\n",
            "Net test dataset size: 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "\n",
        "maxlen_questions = max(len(t) for t in train_df['tokenized_question'].to_list())\n",
        "maxlen_answers = max(len(t) for t in train_df['tokenized_answer'].to_list())\n",
        "\n",
        "encoder_input_data = pad_sequences(train_df['tokenized_question'], maxlen=maxlen_questions, padding='post')\n",
        "print(f'Encoder input data shape: {encoder_input_data.shape}')\n",
        "\n",
        "decoder_input_data = pad_sequences(train_df['tokenized_answer'], maxlen=maxlen_answers, padding='post')\n",
        "print(f'Decoder input data shape: {decoder_input_data.shape}')\n",
        "\n",
        "tokenized_answers = [ ta[1:] for ta in train_df['tokenized_answer'] ]\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "decoder_output_data = to_categorical(padded_answers, vocab_size)\n",
        "print(f'Decoder output data shape: {decoder_output_data.shape}')\n",
        "\n",
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embedding = Embedding(vocab_size, 200, mask_zero=True)(enc_inputs)\n",
        "_, state_h, state_c = LSTM(200, return_state=True)(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(vocab_size, 200, mask_zero=True)(dec_inputs)\n",
        "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "dec_dense = Dense(vocab_size, activation=softmax)\n",
        "output = dec_dense(dec_outputs)\n",
        "\n",
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzFFnaCE5TIe",
        "outputId": "9c5da99e-f95e-4ccf-b943-b41c27785333"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input data shape: (2181, 21)\n",
            "Decoder input data shape: (2181, 52)\n",
            "Decoder output data shape: (2181, 52, 6001)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 200)    1200200     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    1200200     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 200),        320800      ['embedding_2[0][0]']            \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 200),  320800      ['embedding_3[0][0]',            \n",
            "                                 (None, 200),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 6001)   1206201     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,248,201\n",
            "Trainable params: 4,248,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_output_data, batch_size=50, epochs=200, validation_split=0.05)\n",
        "#model.save('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glC5E6w1M9mk",
        "outputId": "6f123a9b-2c28-4c5a-c67f-6d432bbf8bf9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "42/42 [==============================] - 14s 107ms/step - loss: 2.2081 - val_loss: 1.9894\n",
            "Epoch 2/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 2.0007 - val_loss: 1.9501\n",
            "Epoch 3/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.9352 - val_loss: 1.9386\n",
            "Epoch 4/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.8837 - val_loss: 1.9212\n",
            "Epoch 5/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 1.8403 - val_loss: 1.9109\n",
            "Epoch 6/200\n",
            "42/42 [==============================] - 2s 42ms/step - loss: 1.7996 - val_loss: 1.9005\n",
            "Epoch 7/200\n",
            "42/42 [==============================] - 2s 39ms/step - loss: 1.7638 - val_loss: 1.8996\n",
            "Epoch 8/200\n",
            "42/42 [==============================] - 2s 40ms/step - loss: 1.7312 - val_loss: 1.8974\n",
            "Epoch 9/200\n",
            "42/42 [==============================] - 2s 41ms/step - loss: 1.7018 - val_loss: 1.8953\n",
            "Epoch 10/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 1.6725 - val_loss: 1.8876\n",
            "Epoch 11/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.6435 - val_loss: 1.8891\n",
            "Epoch 12/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.6148 - val_loss: 1.8934\n",
            "Epoch 13/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.5855 - val_loss: 1.8889\n",
            "Epoch 14/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.5561 - val_loss: 1.8944\n",
            "Epoch 15/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.5271 - val_loss: 1.8888\n",
            "Epoch 16/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.4979 - val_loss: 1.8913\n",
            "Epoch 17/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.4684 - val_loss: 1.9003\n",
            "Epoch 18/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.4392 - val_loss: 1.8903\n",
            "Epoch 19/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.4105 - val_loss: 1.8923\n",
            "Epoch 20/200\n",
            "42/42 [==============================] - 2s 41ms/step - loss: 1.3814 - val_loss: 1.9020\n",
            "Epoch 21/200\n",
            "42/42 [==============================] - 2s 40ms/step - loss: 1.3535 - val_loss: 1.9019\n",
            "Epoch 22/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 1.3243 - val_loss: 1.8979\n",
            "Epoch 23/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.2963 - val_loss: 1.9103\n",
            "Epoch 24/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.2685 - val_loss: 1.9075\n",
            "Epoch 25/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.2400 - val_loss: 1.9163\n",
            "Epoch 26/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 1.2124 - val_loss: 1.9261\n",
            "Epoch 27/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.1850 - val_loss: 1.9257\n",
            "Epoch 28/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.1581 - val_loss: 1.9355\n",
            "Epoch 29/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.1306 - val_loss: 1.9392\n",
            "Epoch 30/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 1.1033 - val_loss: 1.9429\n",
            "Epoch 31/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.0787 - val_loss: 1.9500\n",
            "Epoch 32/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.0511 - val_loss: 1.9524\n",
            "Epoch 33/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 1.0260 - val_loss: 1.9597\n",
            "Epoch 34/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 1.0003 - val_loss: 1.9697\n",
            "Epoch 35/200\n",
            "42/42 [==============================] - 2s 39ms/step - loss: 0.9751 - val_loss: 1.9784\n",
            "Epoch 36/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.9498 - val_loss: 1.9857\n",
            "Epoch 37/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.9253 - val_loss: 1.9952\n",
            "Epoch 38/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.9015 - val_loss: 2.0019\n",
            "Epoch 39/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.8771 - val_loss: 2.0052\n",
            "Epoch 40/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.8538 - val_loss: 2.0257\n",
            "Epoch 41/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.8308 - val_loss: 2.0272\n",
            "Epoch 42/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.8076 - val_loss: 2.0322\n",
            "Epoch 43/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.7852 - val_loss: 2.0525\n",
            "Epoch 44/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.7632 - val_loss: 2.0584\n",
            "Epoch 45/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.7414 - val_loss: 2.0698\n",
            "Epoch 46/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.7208 - val_loss: 2.0708\n",
            "Epoch 47/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.6994 - val_loss: 2.0792\n",
            "Epoch 48/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.6789 - val_loss: 2.0848\n",
            "Epoch 49/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.6582 - val_loss: 2.0977\n",
            "Epoch 50/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.6382 - val_loss: 2.1151\n",
            "Epoch 51/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.6192 - val_loss: 2.1315\n",
            "Epoch 52/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.5996 - val_loss: 2.1249\n",
            "Epoch 53/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.5821 - val_loss: 2.1529\n",
            "Epoch 54/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.5631 - val_loss: 2.1628\n",
            "Epoch 55/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.5455 - val_loss: 2.1622\n",
            "Epoch 56/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.5283 - val_loss: 2.1815\n",
            "Epoch 57/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.5121 - val_loss: 2.1869\n",
            "Epoch 58/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.4952 - val_loss: 2.2045\n",
            "Epoch 59/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.4784 - val_loss: 2.2208\n",
            "Epoch 60/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 0.4630 - val_loss: 2.2141\n",
            "Epoch 61/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.4473 - val_loss: 2.2298\n",
            "Epoch 62/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.4319 - val_loss: 2.2339\n",
            "Epoch 63/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.4174 - val_loss: 2.2572\n",
            "Epoch 64/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.4032 - val_loss: 2.2672\n",
            "Epoch 65/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 0.3894 - val_loss: 2.2757\n",
            "Epoch 66/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.3757 - val_loss: 2.2822\n",
            "Epoch 67/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.3619 - val_loss: 2.2928\n",
            "Epoch 68/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.3492 - val_loss: 2.3035\n",
            "Epoch 69/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.3372 - val_loss: 2.3203\n",
            "Epoch 70/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.3241 - val_loss: 2.3395\n",
            "Epoch 71/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.3123 - val_loss: 2.3405\n",
            "Epoch 72/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.3012 - val_loss: 2.3442\n",
            "Epoch 73/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2900 - val_loss: 2.3570\n",
            "Epoch 74/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2787 - val_loss: 2.3728\n",
            "Epoch 75/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2679 - val_loss: 2.3854\n",
            "Epoch 76/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.2584 - val_loss: 2.3856\n",
            "Epoch 77/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.2481 - val_loss: 2.4144\n",
            "Epoch 78/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.2383 - val_loss: 2.4180\n",
            "Epoch 79/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.2293 - val_loss: 2.4140\n",
            "Epoch 80/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.2202 - val_loss: 2.4214\n",
            "Epoch 81/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.2121 - val_loss: 2.4501\n",
            "Epoch 82/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.2031 - val_loss: 2.4646\n",
            "Epoch 83/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1953 - val_loss: 2.4548\n",
            "Epoch 84/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1876 - val_loss: 2.4805\n",
            "Epoch 85/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1793 - val_loss: 2.4910\n",
            "Epoch 86/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1729 - val_loss: 2.4954\n",
            "Epoch 87/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1659 - val_loss: 2.4927\n",
            "Epoch 88/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1591 - val_loss: 2.5104\n",
            "Epoch 89/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1531 - val_loss: 2.5232\n",
            "Epoch 90/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1468 - val_loss: 2.5199\n",
            "Epoch 91/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1407 - val_loss: 2.5362\n",
            "Epoch 92/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1346 - val_loss: 2.5450\n",
            "Epoch 93/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1295 - val_loss: 2.5606\n",
            "Epoch 94/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1241 - val_loss: 2.5740\n",
            "Epoch 95/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1191 - val_loss: 2.5859\n",
            "Epoch 96/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.1148 - val_loss: 2.5840\n",
            "Epoch 97/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1104 - val_loss: 2.5883\n",
            "Epoch 98/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1055 - val_loss: 2.6165\n",
            "Epoch 99/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.1013 - val_loss: 2.6167\n",
            "Epoch 100/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0979 - val_loss: 2.6212\n",
            "Epoch 101/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0938 - val_loss: 2.6392\n",
            "Epoch 102/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0900 - val_loss: 2.6424\n",
            "Epoch 103/200\n",
            "42/42 [==============================] - 2s 38ms/step - loss: 0.0866 - val_loss: 2.6708\n",
            "Epoch 104/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0832 - val_loss: 2.6610\n",
            "Epoch 105/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0806 - val_loss: 2.6802\n",
            "Epoch 106/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0778 - val_loss: 2.6718\n",
            "Epoch 107/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0747 - val_loss: 2.6833\n",
            "Epoch 108/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0719 - val_loss: 2.7151\n",
            "Epoch 109/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0695 - val_loss: 2.7074\n",
            "Epoch 110/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0676 - val_loss: 2.7090\n",
            "Epoch 111/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0651 - val_loss: 2.7285\n",
            "Epoch 112/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0626 - val_loss: 2.7224\n",
            "Epoch 113/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0611 - val_loss: 2.7321\n",
            "Epoch 114/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0592 - val_loss: 2.7391\n",
            "Epoch 115/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0573 - val_loss: 2.7578\n",
            "Epoch 116/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0556 - val_loss: 2.7639\n",
            "Epoch 117/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0540 - val_loss: 2.7610\n",
            "Epoch 118/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0525 - val_loss: 2.7837\n",
            "Epoch 119/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0512 - val_loss: 2.7806\n",
            "Epoch 120/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0496 - val_loss: 2.8147\n",
            "Epoch 121/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0485 - val_loss: 2.8033\n",
            "Epoch 122/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0473 - val_loss: 2.8036\n",
            "Epoch 123/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0462 - val_loss: 2.8089\n",
            "Epoch 124/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0453 - val_loss: 2.8326\n",
            "Epoch 125/200\n",
            "42/42 [==============================] - 2s 39ms/step - loss: 0.0442 - val_loss: 2.8389\n",
            "Epoch 126/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0431 - val_loss: 2.8443\n",
            "Epoch 127/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0425 - val_loss: 2.8541\n",
            "Epoch 128/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0416 - val_loss: 2.8510\n",
            "Epoch 129/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0406 - val_loss: 2.8600\n",
            "Epoch 130/200\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0401 - val_loss: 2.8539\n",
            "Epoch 131/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0393 - val_loss: 2.8736\n",
            "Epoch 132/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0386 - val_loss: 2.8685\n",
            "Epoch 133/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0382 - val_loss: 2.8917\n",
            "Epoch 134/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0376 - val_loss: 2.8904\n",
            "Epoch 135/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0370 - val_loss: 2.8897\n",
            "Epoch 136/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0364 - val_loss: 2.8988\n",
            "Epoch 137/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0359 - val_loss: 2.9094\n",
            "Epoch 138/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0355 - val_loss: 2.9158\n",
            "Epoch 139/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0352 - val_loss: 2.9224\n",
            "Epoch 140/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0346 - val_loss: 2.9359\n",
            "Epoch 141/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0343 - val_loss: 2.9269\n",
            "Epoch 142/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0340 - val_loss: 2.9296\n",
            "Epoch 143/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0335 - val_loss: 2.9250\n",
            "Epoch 144/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0333 - val_loss: 2.9415\n",
            "Epoch 145/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0328 - val_loss: 2.9452\n",
            "Epoch 146/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0326 - val_loss: 2.9425\n",
            "Epoch 147/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0325 - val_loss: 2.9604\n",
            "Epoch 148/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0318 - val_loss: 2.9556\n",
            "Epoch 149/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0319 - val_loss: 2.9595\n",
            "Epoch 150/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0317 - val_loss: 2.9711\n",
            "Epoch 151/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0312 - val_loss: 2.9746\n",
            "Epoch 152/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0311 - val_loss: 2.9852\n",
            "Epoch 153/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0309 - val_loss: 2.9930\n",
            "Epoch 154/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0309 - val_loss: 2.9862\n",
            "Epoch 155/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0305 - val_loss: 2.9984\n",
            "Epoch 156/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0306 - val_loss: 3.0000\n",
            "Epoch 157/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0302 - val_loss: 3.0040\n",
            "Epoch 158/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0300 - val_loss: 2.9936\n",
            "Epoch 159/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0299 - val_loss: 3.0351\n",
            "Epoch 160/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0298 - val_loss: 3.0263\n",
            "Epoch 161/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0297 - val_loss: 3.0392\n",
            "Epoch 162/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0293 - val_loss: 3.0471\n",
            "Epoch 163/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0294 - val_loss: 3.0369\n",
            "Epoch 164/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0292 - val_loss: 3.0488\n",
            "Epoch 165/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0290 - val_loss: 3.0749\n",
            "Epoch 166/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0289 - val_loss: 3.0570\n",
            "Epoch 167/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0288 - val_loss: 3.0399\n",
            "Epoch 168/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0287 - val_loss: 3.0721\n",
            "Epoch 169/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0286 - val_loss: 3.0593\n",
            "Epoch 170/200\n",
            "42/42 [==============================] - 1s 36ms/step - loss: 0.0285 - val_loss: 3.0687\n",
            "Epoch 171/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0284 - val_loss: 3.0615\n",
            "Epoch 172/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0282 - val_loss: 3.0755\n",
            "Epoch 173/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0281 - val_loss: 3.0980\n",
            "Epoch 174/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0282 - val_loss: 3.0948\n",
            "Epoch 175/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0280 - val_loss: 3.0811\n",
            "Epoch 176/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0279 - val_loss: 3.1011\n",
            "Epoch 177/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0280 - val_loss: 3.1010\n",
            "Epoch 178/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0277 - val_loss: 3.1232\n",
            "Epoch 179/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0276 - val_loss: 3.1109\n",
            "Epoch 180/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0275 - val_loss: 3.1124\n",
            "Epoch 181/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0275 - val_loss: 3.1083\n",
            "Epoch 182/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0274 - val_loss: 3.1209\n",
            "Epoch 183/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0273 - val_loss: 3.1293\n",
            "Epoch 184/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0272 - val_loss: 3.1436\n",
            "Epoch 185/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0272 - val_loss: 3.1458\n",
            "Epoch 186/200\n",
            "42/42 [==============================] - 1s 35ms/step - loss: 0.0271 - val_loss: 3.1287\n",
            "Epoch 187/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0272 - val_loss: 3.1462\n",
            "Epoch 188/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0271 - val_loss: 3.1700\n",
            "Epoch 189/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0272 - val_loss: 3.1353\n",
            "Epoch 190/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0269 - val_loss: 3.1644\n",
            "Epoch 191/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0269 - val_loss: 3.1568\n",
            "Epoch 192/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0269 - val_loss: 3.1647\n",
            "Epoch 193/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0268 - val_loss: 3.1771\n",
            "Epoch 194/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0268 - val_loss: 3.1518\n",
            "Epoch 195/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0269 - val_loss: 3.1890\n",
            "Epoch 196/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0266 - val_loss: 3.1785\n",
            "Epoch 197/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0265 - val_loss: 3.1911\n",
            "Epoch 198/200\n",
            "42/42 [==============================] - 2s 37ms/step - loss: 0.0268 - val_loss: 3.1698\n",
            "Epoch 199/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0265 - val_loss: 3.1778\n",
            "Epoch 200/200\n",
            "42/42 [==============================] - 2s 36ms/step - loss: 0.0266 - val_loss: 3.1908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ea3441190>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare models for inferencing (separate encoder, decoder)\n",
        "#model.load_weights('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n",
        "\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = Input(shape=(200,))\n",
        "    dec_state_input_c = Input(shape=(200,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                             initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    print('Inference encoder:')\n",
        "    enc_model.summary()\n",
        "    return enc_model, dec_model\n",
        "\n",
        "\n",
        "# Also here: need to change to lemmas in case we do that on training data\n",
        "# (see above)\n",
        "# Furthermore, there'd be a more compact way of expressing\n",
        "# below code... but for simplicity, taken from example for time being\n",
        "def str_to_tokens(sentence):\n",
        "    words = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", sentence).lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')\n",
        "\n",
        "\n",
        "enc_model, dec_model = make_inference_models()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHYIs3pL86Ov",
        "outputId": "5fb04355-fdbf-4086-ab6a-25cdc4f6e02f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    1200200     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 200),  320800      ['embedding_3[0][0]',            \n",
            "                                 (None, 200),                     'input_7[0][0]',                \n",
            "                                 (None, 200)]                     'input_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 6001)   1206201     ['lstm_3[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,727,201\n",
            "Trainable params: 2,727,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 200)         1200200   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, 200),             320800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,521,000\n",
            "Trainable params: 1,521,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get 100 random numbers to choose random sentences and calculate BLEU score\n",
        "# note that code must be refactored: it was merged from examples and is \n",
        "# inconsistent now\n",
        "questions = test_df['Question'].to_list()\n",
        "rand_integers = [random.randint(0, len(questions)-1) for i in range(1, 10)]\n",
        "bleu_total = 0\n",
        "\n",
        "\n",
        "for i in rand_integers:\n",
        "    states_values = enc_model.predict(str_to_tokens(questions[i]))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    decoded_translation = decoded_translation[1:]\n",
        "\n",
        "    print(f'Original question: {questions[i]}')\n",
        "    print(f'Predicated answer: {decoded_translation}')\n",
        "\n",
        "    reference_answers = test_df.loc[test_df['Question']==questions[i], 'norm_answer'].to_list()\n",
        "    reference_answers = [answer[8:-7] for answer in reference_answers]\n",
        "\n",
        "\n",
        "    # The following should contain all possible answers, though...\n",
        "    print(f'{reference_answers}')\n",
        "    bleu_score = sentence_bleu(reference_answers, decoded_translation, smoothing_function=SmoothingFunction().method0)\n",
        "    print(f'Bleu score: {bleu_score}\\n')\n",
        "    bleu_total += bleu_score\n",
        "\n",
        "print(f'Bleu average = {bleu_total/len(rand_integers)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QObKQwyVLNzY",
        "outputId": "27134014-32a5-41a6-9f77-6da2bc1a528a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original question: How Rich Is Donald Trump\n",
            "Predicated answer: in february 1965 less than in peace and has sold more than 200 million records worldwide a new eastern eastern eastern june people\n",
            "['he was given control of the company in 1971 and renamed it the trump organization', 'in 2010 trump expressed an interest in becoming a candidate for president of the united states in the 2012 election  though in may 2011 he announced he would not be a candidate']\n",
            "Bleu score: 0.20543609327783416\n",
            "\n",
            "Original question: what are points on a mortgage\n",
            "Predicated answer: the other phenomenon is a small piece of paper fantasy novels that of the british empire is considered to be a different format\n",
            "['points may also be purchased to reduce the monthly payment for the purpose of qualifying for a loan', \"also directly related to points is the concept of the ' no closing cost loan '\", 'when premium is earned by making the note rate higher this premium is sometimes used to pay the closing costs']\n",
            "Bleu score: 0.4271708307292178\n",
            "\n",
            "Original question: what is a day care for?\n",
            "Predicated answer: vitamin a web is a legal form of the seller that means a health reaction\n",
            "['the service is known as child care in the united kingdom and australia and child care or day care in north america although child care also has a broader meaning']\n",
            "Bleu score: 0.10695412348492529\n",
            "\n",
            "Original question: how many members are in the house of representatives\n",
            "Predicated answer: the other is benjamin franklin on the 100\n",
            "['it is frequently referred to as the house', 'the other house is the senate ', 'the composition and powers of the house are established in article one of the united states constitution ', 'each us state is represented in the house in proportion to its population but is entitled to at least one representative ', 'the house meets in the south wing of the united states capitol ']\n",
            "Bleu score: 0.5594172107063934\n",
            "\n",
            "Original question: who owns fox news\n",
            "Predicated answer: it was the first of the first recorded series that served as in both during 2011\n",
            "[\"it is the world's secondlargest media group as of 2011 in terms of revenue and the world's third largest in entertainment as of 2009\"]\n",
            "Bleu score: 0.2150960095141905\n",
            "\n",
            "Original question: what is the purpose of child support?\n",
            "Predicated answer: it is the largest city in england new york or the 2005\n",
            "['in family law and public policy child support or child maintenance is an ongoing periodic payment made by a parent for the financial benefit of a child following the end of a marriage or other relationship']\n",
            "Bleu score: 0.026504563993164264\n",
            "\n",
            "Original question: what religion is church of christ\n",
            "Predicated answer: it is the largest city in northern california to the south and west by the european union\n",
            "['the term church of christ may refer to', 'a body of christians who continue to use only the new testament as the source for christian doctrine and practice and who consider themselves to be part of the original church in contrast to orthodox christianity catholic christianity or protestant christianity', 'the eastern orthodox or roman catholic churches primarily used by members of these churches', 'churches of christ', 'christian churches and churches of christ', 'christian church disciples of christ', 'churches of christ in australia', 'other historically related groups', 'churches of christ in christian union', 'denominations with a shared heritage in the latter day saint movement  which include', 'and other denominations called the church of jesus christ']\n",
            "Bleu score: 0.656717688801431\n",
            "\n",
            "Original question: who is charlie in 90210\n",
            "Predicated answer: it was the only fashion designer to appear on time magazine's terms of the 100 and artists of the world and in 2001\n",
            "['season 3 cast image featuring the young cast who have been with the series the longest', 'this is a list of the characters that have appeared on 90210  an american teen drama ']\n",
            "Bleu score: 0.34378186016577894\n",
            "\n",
            "Original question: who is charlie in 90210\n",
            "Predicated answer: it was the only fashion designer to appear on time magazine's terms of the 100 and artists of the world and in 2001\n",
            "['season 3 cast image featuring the young cast who have been with the series the longest', 'this is a list of the characters that have appeared on 90210  an american teen drama ']\n",
            "Bleu score: 0.34378186016577894\n",
            "\n",
            "Bleu average = 0.3205400267598571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input('Ask me something, or enter \\'end\\' to stop: ')\n",
        "    if question == 'end':\n",
        "        break\n",
        "    states_values = enc_model.predict(str_to_tokens(question))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "metadata": {
        "id": "KAsbo2TRkAsh",
        "outputId": "53aecb68-9ca0-4b89-efd2-28d15b78ae8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask me something, or enter 'end' to stop: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "ny-x6HP6wrg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "1de6beed-906b-46fb-f9a1-81e696ded6bd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     QuestionID                                           Question DocumentID  \\\n",
              "43          Q33                         how are antibodies used in        D33   \n",
              "49          Q33                         how are antibodies used in        D33   \n",
              "169         Q86  how close or far do you want to be to the stan...        D86   \n",
              "173         Q86  how close or far do you want to be to the stan...        D86   \n",
              "179         Q86  how close or far do you want to be to the stan...        D86   \n",
              "...         ...                                                ...        ...   \n",
              "5749      Q2880                       where was martin luther born      D2671   \n",
              "5773      Q2892                   what was the first mario 3D game      D1077   \n",
              "5952      Q2953               what is the us system of measurement      D2730   \n",
              "6021      Q2981     WHAT WAS THE WEATHER LIKE ON FEBRUARY 12, 1909      D2754   \n",
              "6024      Q2981     WHAT WAS THE WEATHER LIKE ON FEBRUARY 12, 1909      D2754   \n",
              "\n",
              "                            DocumentTitle SentenceID  \\\n",
              "43                               antibody     D33-15   \n",
              "49                               antibody     D33-21   \n",
              "169                    Standard deviation      D86-3   \n",
              "173                    Standard deviation      D86-7   \n",
              "179                    Standard deviation     D86-13   \n",
              "...                                   ...        ...   \n",
              "5749                        Martin Luther   D2671-12   \n",
              "5773  List of video games featuring Mario    D1077-3   \n",
              "5952        United States customary units    D2730-6   \n",
              "6021                        February 1909    D2754-0   \n",
              "6024                        February 1909    D2754-3   \n",
              "\n",
              "                                               Sentence  Label  \\\n",
              "43    Though the general structure of all antibodies...      0   \n",
              "49    This allows a single antibody to be used by se...      0   \n",
              "169   A low standard deviation indicates that the da...      0   \n",
              "173   Note, however, that for measurements with perc...      0   \n",
              "179   When only a sample of data from a population i...      0   \n",
              "...                                                 ...    ...   \n",
              "5749  These statements have contributed to his contr...      0   \n",
              "5773  The year indicated is the year the game was fi...      0   \n",
              "5952  The U.S. does not primarily use SI units in it...      0   \n",
              "6021  January â February â March â April â M...      0   \n",
              "6024    The following events occurred in February 1909.      0   \n",
              "\n",
              "                                          norm_question  \\\n",
              "43                           how are antibodies used in   \n",
              "49                           how are antibodies used in   \n",
              "169   how close or far do you want to be to the stan...   \n",
              "173   how close or far do you want to be to the stan...   \n",
              "179   how close or far do you want to be to the stan...   \n",
              "...                                                 ...   \n",
              "5749                       where was martin luther born   \n",
              "5773                   what was the first mario 3d game   \n",
              "5952               what is the us system of measurement   \n",
              "6021      what was the weather like on february 12 1909   \n",
              "6024      what was the weather like on february 12 1909   \n",
              "\n",
              "                                            norm_answer  \\\n",
              "43    _START_ though the general structure of all an...   \n",
              "49    _START_ this allows a single antibody to be us...   \n",
              "169   _START_ a low standard deviation indicates tha...   \n",
              "173   _START_ note however that for measurements wit...   \n",
              "179   _START_ when only a sample of data from a popu...   \n",
              "...                                                 ...   \n",
              "5749  _START_ these statements have contributed to h...   \n",
              "5773  _START_ the year indicated is the year the gam...   \n",
              "5952  _START_ the us does not primarily use si units...   \n",
              "6021  _START_ january â february â march â apr...   \n",
              "6024  _START_ the following events occurred in febru...   \n",
              "\n",
              "                                     tokenized_question  \\\n",
              "43                                [15, 14, 1961, 47, 5]   \n",
              "49                                [15, 14, 1961, 47, 5]   \n",
              "169   [15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...   \n",
              "173   [15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...   \n",
              "179   [15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...   \n",
              "...                                                 ...   \n",
              "5749                          [28, 11, 1051, 1859, 111]   \n",
              "5773                    [9, 11, 1, 38, 4315, 1726, 109]   \n",
              "5952                         [9, 7, 1, 49, 91, 3, 3076]   \n",
              "6021           [9, 11, 1, 895, 170, 17, 543, 494, 5931]   \n",
              "6024           [9, 11, 1, 895, 170, 17, 543, 494, 5931]   \n",
              "\n",
              "                                       tokenized_answer  question_tokens  \\\n",
              "43    [2, 359, 1, 230, 1166, 3, 62, 1961, 7, 329, 51...                5   \n",
              "49    [2, 52, 1557, 8, 216, 4774, 10, 35, 47, 16, 14...                5   \n",
              "169   [2, 8, 714, 280, 2088, 2454, 25, 1, 260, 1766,...               13   \n",
              "173   [2, 1538, 166, 25, 13, 4421, 18, 671, 12, 587,...               13   \n",
              "179   [2, 22, 84, 8, 3898, 3, 260, 21, 8, 105, 7, 65...               13   \n",
              "...                                                 ...              ...   \n",
              "5749    [2, 102, 3833, 34, 2991, 10, 36, 2571, 1365, 4]                5   \n",
              "5773  [2, 1, 75, 5634, 7, 1, 75, 1, 109, 11, 38, 148...                7   \n",
              "5952  [2, 1, 49, 29, 55, 653, 82, 2461, 943, 5, 45, ...                7   \n",
              "6021  [2, 333, 237, 543, 237, 262, 237, 267, 237, 69...                9   \n",
              "6024            [2, 1, 253, 523, 2107, 5, 543, 5931, 4]                9   \n",
              "\n",
              "      answer_tokens  \n",
              "43               39  \n",
              "49               18  \n",
              "169              36  \n",
              "173              20  \n",
              "179              31  \n",
              "...             ...  \n",
              "5749             10  \n",
              "5773             29  \n",
              "5952             35  \n",
              "6021             25  \n",
              "6024              9  \n",
              "\n",
              "[252 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceed3caf-b8b2-47c8-aa24-d3d2f39db5e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>Question</th>\n",
              "      <th>DocumentID</th>\n",
              "      <th>DocumentTitle</th>\n",
              "      <th>SentenceID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>norm_question</th>\n",
              "      <th>norm_answer</th>\n",
              "      <th>tokenized_question</th>\n",
              "      <th>tokenized_answer</th>\n",
              "      <th>question_tokens</th>\n",
              "      <th>answer_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Q33</td>\n",
              "      <td>how are antibodies used in</td>\n",
              "      <td>D33</td>\n",
              "      <td>antibody</td>\n",
              "      <td>D33-15</td>\n",
              "      <td>Though the general structure of all antibodies...</td>\n",
              "      <td>0</td>\n",
              "      <td>how are antibodies used in</td>\n",
              "      <td>_START_ though the general structure of all an...</td>\n",
              "      <td>[15, 14, 1961, 47, 5]</td>\n",
              "      <td>[2, 359, 1, 230, 1166, 3, 62, 1961, 7, 329, 51...</td>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Q33</td>\n",
              "      <td>how are antibodies used in</td>\n",
              "      <td>D33</td>\n",
              "      <td>antibody</td>\n",
              "      <td>D33-21</td>\n",
              "      <td>This allows a single antibody to be used by se...</td>\n",
              "      <td>0</td>\n",
              "      <td>how are antibodies used in</td>\n",
              "      <td>_START_ this allows a single antibody to be us...</td>\n",
              "      <td>[15, 14, 1961, 47, 5]</td>\n",
              "      <td>[2, 52, 1557, 8, 216, 4774, 10, 35, 47, 16, 14...</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Q86</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>D86</td>\n",
              "      <td>Standard deviation</td>\n",
              "      <td>D86-3</td>\n",
              "      <td>A low standard deviation indicates that the da...</td>\n",
              "      <td>0</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>_START_ a low standard deviation indicates tha...</td>\n",
              "      <td>[15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...</td>\n",
              "      <td>[2, 8, 714, 280, 2088, 2454, 25, 1, 260, 1766,...</td>\n",
              "      <td>13</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>Q86</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>D86</td>\n",
              "      <td>Standard deviation</td>\n",
              "      <td>D86-7</td>\n",
              "      <td>Note, however, that for measurements with perc...</td>\n",
              "      <td>0</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>_START_ note however that for measurements wit...</td>\n",
              "      <td>[15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...</td>\n",
              "      <td>[2, 1538, 166, 25, 13, 4421, 18, 671, 12, 587,...</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Q86</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>D86</td>\n",
              "      <td>Standard deviation</td>\n",
              "      <td>D86-13</td>\n",
              "      <td>When only a sample of data from a population i...</td>\n",
              "      <td>0</td>\n",
              "      <td>how close or far do you want to be to the stan...</td>\n",
              "      <td>_START_ when only a sample of data from a popu...</td>\n",
              "      <td>[15, 1366, 20, 900, 48, 178, 2547, 10, 35, 10,...</td>\n",
              "      <td>[2, 22, 84, 8, 3898, 3, 260, 21, 8, 105, 7, 65...</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5749</th>\n",
              "      <td>Q2880</td>\n",
              "      <td>where was martin luther born</td>\n",
              "      <td>D2671</td>\n",
              "      <td>Martin Luther</td>\n",
              "      <td>D2671-12</td>\n",
              "      <td>These statements have contributed to his contr...</td>\n",
              "      <td>0</td>\n",
              "      <td>where was martin luther born</td>\n",
              "      <td>_START_ these statements have contributed to h...</td>\n",
              "      <td>[28, 11, 1051, 1859, 111]</td>\n",
              "      <td>[2, 102, 3833, 34, 2991, 10, 36, 2571, 1365, 4]</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5773</th>\n",
              "      <td>Q2892</td>\n",
              "      <td>what was the first mario 3D game</td>\n",
              "      <td>D1077</td>\n",
              "      <td>List of video games featuring Mario</td>\n",
              "      <td>D1077-3</td>\n",
              "      <td>The year indicated is the year the game was fi...</td>\n",
              "      <td>0</td>\n",
              "      <td>what was the first mario 3d game</td>\n",
              "      <td>_START_ the year indicated is the year the gam...</td>\n",
              "      <td>[9, 11, 1, 38, 4315, 1726, 109]</td>\n",
              "      <td>[2, 1, 75, 5634, 7, 1, 75, 1, 109, 11, 38, 148...</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5952</th>\n",
              "      <td>Q2953</td>\n",
              "      <td>what is the us system of measurement</td>\n",
              "      <td>D2730</td>\n",
              "      <td>United States customary units</td>\n",
              "      <td>D2730-6</td>\n",
              "      <td>The U.S. does not primarily use SI units in it...</td>\n",
              "      <td>0</td>\n",
              "      <td>what is the us system of measurement</td>\n",
              "      <td>_START_ the us does not primarily use si units...</td>\n",
              "      <td>[9, 7, 1, 49, 91, 3, 3076]</td>\n",
              "      <td>[2, 1, 49, 29, 55, 653, 82, 2461, 943, 5, 45, ...</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6021</th>\n",
              "      <td>Q2981</td>\n",
              "      <td>WHAT WAS THE WEATHER LIKE ON FEBRUARY 12, 1909</td>\n",
              "      <td>D2754</td>\n",
              "      <td>February 1909</td>\n",
              "      <td>D2754-0</td>\n",
              "      <td>January â February â March â April â M...</td>\n",
              "      <td>0</td>\n",
              "      <td>what was the weather like on february 12 1909</td>\n",
              "      <td>_START_ january â february â march â apr...</td>\n",
              "      <td>[9, 11, 1, 895, 170, 17, 543, 494, 5931]</td>\n",
              "      <td>[2, 333, 237, 543, 237, 262, 237, 267, 237, 69...</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6024</th>\n",
              "      <td>Q2981</td>\n",
              "      <td>WHAT WAS THE WEATHER LIKE ON FEBRUARY 12, 1909</td>\n",
              "      <td>D2754</td>\n",
              "      <td>February 1909</td>\n",
              "      <td>D2754-3</td>\n",
              "      <td>The following events occurred in February 1909.</td>\n",
              "      <td>0</td>\n",
              "      <td>what was the weather like on february 12 1909</td>\n",
              "      <td>_START_ the following events occurred in febru...</td>\n",
              "      <td>[9, 11, 1, 895, 170, 17, 543, 494, 5931]</td>\n",
              "      <td>[2, 1, 253, 523, 2107, 5, 543, 5931, 4]</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>252 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceed3caf-b8b2-47c8-aa24-d3d2f39db5e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ceed3caf-b8b2-47c8-aa24-d3d2f39db5e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ceed3caf-b8b2-47c8-aa24-d3d2f39db5e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ZYEEr1fFqUm"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}