{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCK507_Team_A_WikiQA_Chatbot_1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/benschlup/csck507_team_a/blob/main/CSCK507_Team_A_ChatBot_THREE.ipynb",
      "authorship_tag": "ABX9TyOzb+riwrHgtzPCHnEV8qtk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschlup/csck504assemblyfactory/blob/main/CSCK507_Team_A_WikiQA_Chatbot_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **CSCK507 Natural Language Processing, March-May 2022: End-of-Module Assignment**\n",
        "# **Generative Chatbot**\n",
        "---\n",
        "#### Team A\n",
        "Muhammad Ali (Student ID )  \n",
        "Benjamin Schlup (Student ID 200050007)  \n",
        "Chinedu Abonyi (Student ID )  \n",
        "Victor Armenta-Valdes (Student ID )\n",
        "\n",
        "---\n",
        "# **Solution 1: LSTM without Attention Layer**\n",
        "---"
      ],
      "metadata": {
        "id": "dXeItkpo51bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset being used: https://www.microsoft.com/en-us/download/details.aspx?id=52419  \n",
        "Paper on dataset: https://aclanthology.org/D15-1237/  \n",
        "Solution inspired by https://medium.com/swlh/how-to-design-seq2seq-chatbot-using-keras-framework-ae86d950e91d  \n",
        "\n",
        "Additional interesting materials to review, and potentially reference:\n",
        "Khin, N.N., Soe, K.M., 2020. Question Answering based University Chatbot using Sequence to Sequence Model, in: .. doi:10.1109/o-cocosda50338.2020.9295021\n",
        "\n"
      ],
      "metadata": {
        "id": "kv0kmUiLmJSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Backlog:\n",
        "* Check if lemmatizing on question side improves performance\n",
        "* Check if word embedding (e.g. using Word2Vec or GloVe) improves performance (beware of out-of-vocab)\n",
        "---"
      ],
      "metadata": {
        "id": "AHuZjEDChQ_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration"
      ],
      "metadata": {
        "id": "subk2_v1tjeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset includes invalid answers (labelled 0) and some questions \n",
        "# even have no valid answer at all: Switches allow test runs excluding invalid\n",
        "# answers.\n",
        "# Note that the assignment says that answers must be provided by the chatbot: \n",
        "# there is no mention that answers must be correct!\n",
        "train_with_invalid_answers = False\n",
        "validate_with_invalid_answers = False\n",
        "test_questions_without_valid_answers = False\n",
        "\n",
        "# The dataset contains questions with multiple valid answers\n",
        "train_with_duplicate_questions = True\n",
        "validate_with_duplicate_questions = True\n",
        "test_with_duplicate_questions = True"
      ],
      "metadata": {
        "id": "_hFMwuk8td8V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Fq0L8soItfbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import codecs\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import urllib.request\n",
        "import yaml\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#from gensim.models import Word2Vec\n",
        "\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ],
      "metadata": {
        "id": "CmdlY3dO1O_S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the GPU is visible to our runtime\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "metadata": {
        "id": "B9cNSuwm07wi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU we have in place\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ijf1uMKAXnbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33582d90-b4fc-4af8-87fb-425fdd70ce62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 10 22:49:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data: If link does not work any longer, access file manually from here: https://www.microsoft.com/en-us/download/details.aspx?id=52419\n",
        "urllib.request.urlretrieve(\"https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\", \"WikiQACorpus.zip\")"
      ],
      "metadata": {
        "id": "mYkrBnyV1L-E",
        "outputId": "e2ce7d57-a2b4-4f5e-f60f-68b18f8abdb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('WikiQACorpus.zip', <http.client.HTTPMessage at 0x7f5080f1ae90>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files\n",
        "with zipfile.ZipFile('WikiQACorpus.zip', 'r') as zipfile:\n",
        "   zipfile.extractall()"
      ],
      "metadata": {
        "id": "d09_-PN51ois"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import questions and answers: training, validation and test datasets\n",
        "train_df = pd.read_csv( f'./WikiQACorpus/WikiQA-train.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "val_df = pd.read_csv( f'./WikiQACorpus/WikiQA-dev.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv( f'./WikiQACorpus/WikiQA-test.tsv', sep='\\t', encoding='ISO-8859-1')       "
      ],
      "metadata": {
        "id": "e_tpDQAUEiKK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality checks and exploratory data analysis removed: dataset has proven clean\n",
        "# Print gross volumes:\n",
        "print(f'Gross training dataset size: {len(train_df)}')\n",
        "print(f'Gross validation dataset size: {len(val_df)}')\n",
        "print(f'Gross test dataset size: {len(test_df)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPMMJHDhvRsN",
        "outputId": "7114799b-c190-449e-cb9f-a32d130be19c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gross training dataset size: 20347\n",
            "Gross validation dataset size: 2733\n",
            "Gross test dataset size: 6116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove q/a pairs depending on configuration of the notebook\n",
        "if not train_with_invalid_answers:\n",
        "    train_df = train_df[train_df['Label'] == 1]\n",
        "if not validate_with_invalid_answers:\n",
        "    val_df = val_df[val_df['Label'] == 1]\n",
        "if not test_questions_without_valid_answers:\n",
        "    test_df = test_df[test_df['Label'] == 1]"
      ],
      "metadata": {
        "id": "7kJkWGVMs5kJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate questions in case configured to do so\n",
        "if not train_with_duplicate_questions:\n",
        "    train_df.drop_duplicates(subset=['Question'], inplace=True)\n",
        "if not validate_with_duplicate_questions:\n",
        "    validate_df.drop_duplicates(subset=['Question'], inplace=True)\n",
        "if not test_with_duplicate_questions:\n",
        "    test_df.drop_duplicates(subset=['Question'], inplace=True)"
      ],
      "metadata": {
        "id": "6hf9fo1r0PdJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print net volumes\n",
        "print(f'Net training dataset size: {len(train_df)}')\n",
        "print(f'Net validation dataset size: {len(val_df)}')\n",
        "print(f'Net test dataset size: {len(test_df)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b53d00-f3c5-4cda-b680-6963a8c1aac6",
        "id": "LuYn2ANsxSAm"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net training dataset size: 1039\n",
            "Net validation dataset size: 140\n",
            "Net test dataset size: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive normalized questions and answers\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df['norm_question'] = [ re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", q).lower() for q in df['Question'] ]\n",
        "    df['norm_answer'] = [ '_START_ '+re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", s).lower()+' _STOP_' for s in df['Sentence']]"
      ],
      "metadata": {
        "id": "QQ1553hGYQL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fed090-a10c-446c-90bd-59bf8572002b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation:\n",
        "# Tokenization:\n",
        "# Reconsider adding digits to filter later, as encoding of numbers may create excessive vocabulary\n",
        "# Also check reference on handling numbers in NLP: https://arxiv.org/abs/2103.13136\n",
        "# Note that I do not yet train the tokenizer on validation and test datasets - should be challenged. \n",
        "target_regex = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\''\n",
        "tokenizer = Tokenizer(filters=target_regex, num_words=5000+1)\n",
        "tokenizer.fit_on_texts(train_df['norm_question'] + train_df['norm_answer'])\n",
        "#vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size = 5000+1\n",
        "print(f'Vocabulary size based on training dataset: {vocab_size}')\n",
        "\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df['tokenized_question'] = tokenizer.texts_to_sequences(df['norm_question'])\n",
        "    df['tokenized_answer'] = tokenizer.texts_to_sequences(df['norm_answer'])\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZedlpHo6-62P",
        "outputId": "5051804b-730f-4a4d-dfe3-158d82002ffb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size based on training dataset: 5001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen_questions = max(len(t) for t in train_df['tokenized_question'].to_list())\n",
        "maxlen_answers = max(len(t) for t in train_df['tokenized_answer'].to_list())"
      ],
      "metadata": {
        "id": "Wm2Z00rXDsXP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = pad_sequences(train_df['tokenized_question'], maxlen=maxlen_questions, padding='post')\n",
        "print(f'Encoder input data shape: {encoder_input_data.shape}')\n",
        "\n",
        "decoder_input_data = pad_sequences(train_df['tokenized_answer'], maxlen=maxlen_answers, padding='post')\n",
        "print(f'Decoder input data shape: {decoder_input_data.shape}')\n",
        "\n",
        "tokenized_answers = [ ta[1:] for ta in train_df['tokenized_answer'] ]\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "decoder_output_data = to_categorical(padded_answers, vocab_size)\n",
        "print(f'Decoder output data shape: {decoder_output_data.shape}')\n",
        "\n",
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embedding = Embedding(vocab_size, 200, mask_zero=True)(enc_inputs)\n",
        "_, state_h, state_c = LSTM(200, return_state=True)(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(vocab_size, 200, mask_zero=True)(dec_inputs)\n",
        "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "dec_dense = Dense(vocab_size, activation=softmax)\n",
        "output = dec_dense(dec_outputs)\n",
        "\n",
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzFFnaCE5TIe",
        "outputId": "b05d6ed7-cd3d-47e9-fbaa-89f10bd70a7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input data shape: (1039, 19)\n",
            "Decoder input data shape: (1039, 107)\n",
            "Decoder output data shape: (1039, 107, 5001)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    1000200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1000200     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 5001)   1005201     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,647,201\n",
            "Trainable params: 3,647,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_output_data, batch_size=50, epochs=200, validation_split=0.05)\n",
        "#model.save('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glC5E6w1M9mk",
        "outputId": "0791f0be-6121-4885-946a-259fc0e39201"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "20/20 [==============================] - 4s 230ms/step - loss: 0.3201 - val_loss: 0.3705\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.3121 - val_loss: 0.3895\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.3046 - val_loss: 0.4207\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.2982 - val_loss: 0.4309\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.2912 - val_loss: 0.4516\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.2846 - val_loss: 0.4746\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.2781 - val_loss: 0.4991\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.2713 - val_loss: 0.5149\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.2656 - val_loss: 0.5260\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.2590 - val_loss: 0.5432\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 0.2529 - val_loss: 0.5568\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.2469 - val_loss: 0.5663\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.2421 - val_loss: 0.5807\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.2352 - val_loss: 0.5891\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.2301 - val_loss: 0.6079\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.2231 - val_loss: 0.6231\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.2185 - val_loss: 0.6283\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.2136 - val_loss: 0.6487\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.2088 - val_loss: 0.6473\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.2029 - val_loss: 0.6606\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1982 - val_loss: 0.6693\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1933 - val_loss: 0.6807\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1876 - val_loss: 0.6911\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1837 - val_loss: 0.7098\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1790 - val_loss: 0.7156\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1735 - val_loss: 0.7272\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1705 - val_loss: 0.7274\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.1651 - val_loss: 0.7332\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1613 - val_loss: 0.7575\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1561 - val_loss: 0.7572\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1538 - val_loss: 0.7577\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.1501 - val_loss: 0.7694\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1441 - val_loss: 0.7795\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1413 - val_loss: 0.7891\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1374 - val_loss: 0.8116\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1337 - val_loss: 0.8064\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1290 - val_loss: 0.8249\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1269 - val_loss: 0.8137\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1226 - val_loss: 0.8294\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.1184 - val_loss: 0.8288\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1167 - val_loss: 0.8392\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.1127 - val_loss: 0.8519\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1099 - val_loss: 0.8642\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.1067 - val_loss: 0.8589\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.1039 - val_loss: 0.8657\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.1009 - val_loss: 0.8805\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0968 - val_loss: 0.8897\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0945 - val_loss: 0.8843\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0926 - val_loss: 0.8967\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0896 - val_loss: 0.9166\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0858 - val_loss: 0.9111\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0846 - val_loss: 0.9118\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0825 - val_loss: 0.9263\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0791 - val_loss: 0.9283\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0766 - val_loss: 0.9526\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0746 - val_loss: 0.9397\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0719 - val_loss: 0.9458\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0698 - val_loss: 0.9570\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0681 - val_loss: 0.9687\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0660 - val_loss: 0.9763\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0636 - val_loss: 0.9731\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0616 - val_loss: 0.9829\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0600 - val_loss: 0.9925\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0583 - val_loss: 0.9855\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0556 - val_loss: 1.0206\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0540 - val_loss: 1.0131\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0542 - val_loss: 1.0014\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0508 - val_loss: 1.0178\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0491 - val_loss: 1.0105\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0483 - val_loss: 1.0236\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0465 - val_loss: 1.0349\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0447 - val_loss: 1.0484\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0432 - val_loss: 1.0366\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0422 - val_loss: 1.0558\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0406 - val_loss: 1.0543\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0394 - val_loss: 1.0556\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0383 - val_loss: 1.0649\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0366 - val_loss: 1.0829\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0358 - val_loss: 1.0721\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0354 - val_loss: 1.0815\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0333 - val_loss: 1.0863\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0324 - val_loss: 1.0987\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0312 - val_loss: 1.1035\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0307 - val_loss: 1.1090\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0295 - val_loss: 1.1027\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0282 - val_loss: 1.1160\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0273 - val_loss: 1.1166\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0264 - val_loss: 1.1249\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0259 - val_loss: 1.1225\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0249 - val_loss: 1.1396\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0241 - val_loss: 1.1395\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0230 - val_loss: 1.1422\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0225 - val_loss: 1.1469\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0217 - val_loss: 1.1569\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0214 - val_loss: 1.1518\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0204 - val_loss: 1.1696\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0196 - val_loss: 1.1536\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0192 - val_loss: 1.1767\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0187 - val_loss: 1.1785\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0183 - val_loss: 1.1834\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0174 - val_loss: 1.1830\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0169 - val_loss: 1.1858\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0162 - val_loss: 1.1998\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0159 - val_loss: 1.2010\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0157 - val_loss: 1.2019\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0149 - val_loss: 1.2149\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0145 - val_loss: 1.1998\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0141 - val_loss: 1.2217\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0139 - val_loss: 1.2192\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0133 - val_loss: 1.2166\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0128 - val_loss: 1.2327\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0129 - val_loss: 1.2299\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0121 - val_loss: 1.2344\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0120 - val_loss: 1.2337\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0115 - val_loss: 1.2413\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0112 - val_loss: 1.2363\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0112 - val_loss: 1.2463\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0106 - val_loss: 1.2567\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0103 - val_loss: 1.2468\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0099 - val_loss: 1.2605\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0101 - val_loss: 1.2591\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0095 - val_loss: 1.2602\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0092 - val_loss: 1.2729\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0093 - val_loss: 1.2716\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0090 - val_loss: 1.2881\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0086 - val_loss: 1.2824\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0084 - val_loss: 1.2816\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0083 - val_loss: 1.2893\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0080 - val_loss: 1.3054\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0080 - val_loss: 1.2965\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0078 - val_loss: 1.3165\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0076 - val_loss: 1.3136\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0074 - val_loss: 1.3078\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0073 - val_loss: 1.3079\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0073 - val_loss: 1.3103\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0069 - val_loss: 1.3137\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0068 - val_loss: 1.3135\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0068 - val_loss: 1.3217\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0066 - val_loss: 1.3166\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0065 - val_loss: 1.3330\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0063 - val_loss: 1.3415\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0063 - val_loss: 1.3346\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0061 - val_loss: 1.3391\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0062 - val_loss: 1.3531\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0058 - val_loss: 1.3570\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0058 - val_loss: 1.3636\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0059 - val_loss: 1.3520\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0059 - val_loss: 1.3689\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0055 - val_loss: 1.3641\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0055 - val_loss: 1.3572\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0054 - val_loss: 1.3702\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0055 - val_loss: 1.3653\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0052 - val_loss: 1.3759\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0051 - val_loss: 1.3797\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0051 - val_loss: 1.3788\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0053 - val_loss: 1.3812\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0051 - val_loss: 1.3824\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0048 - val_loss: 1.3892\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0050 - val_loss: 1.3988\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0049 - val_loss: 1.3996\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0047 - val_loss: 1.3976\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0048 - val_loss: 1.4093\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0047 - val_loss: 1.4069\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0046 - val_loss: 1.4208\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0046 - val_loss: 1.4063\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0047 - val_loss: 1.4111\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0044 - val_loss: 1.4191\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0045 - val_loss: 1.4453\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0045 - val_loss: 1.4180\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0043 - val_loss: 1.4412\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0044 - val_loss: 1.4453\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0044 - val_loss: 1.4308\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0043 - val_loss: 1.4270\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0042 - val_loss: 1.4384\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0042 - val_loss: 1.4478\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.0042 - val_loss: 1.4491\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.0042 - val_loss: 1.4409\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0042 - val_loss: 1.4448\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0042 - val_loss: 1.4586\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0041 - val_loss: 1.4555\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0040 - val_loss: 1.4632\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0040 - val_loss: 1.4570\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0040 - val_loss: 1.4551\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0040 - val_loss: 1.4954\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0040 - val_loss: 1.4704\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0041 - val_loss: 1.4755\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0039 - val_loss: 1.4675\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0038 - val_loss: 1.4776\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0038 - val_loss: 1.4778\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0039 - val_loss: 1.4785\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0038 - val_loss: 1.4803\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0040 - val_loss: 1.4835\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 1s 54ms/step - loss: 0.0038 - val_loss: 1.4833\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0037 - val_loss: 1.4884\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.0037 - val_loss: 1.4857\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 0.0038 - val_loss: 1.4952\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0038 - val_loss: 1.5088\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 0.0037 - val_loss: 1.4920\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 0.0038 - val_loss: 1.5036\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 1s 50ms/step - loss: 0.0037 - val_loss: 1.5023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ee7cb4350>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare models for inferencing (separate encoder, decoder)\n",
        "#model.load_weights('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n",
        "\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = Input(shape=(200,))\n",
        "    dec_state_input_c = Input(shape=(200,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                             initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    print('Inference encoder:')\n",
        "    enc_model.summary()\n",
        "    return enc_model, dec_model\n",
        "\n",
        "\n",
        "# Also here: need to change to lemmas in case we do that on training data\n",
        "# (see above)\n",
        "# Furthermore, there'd be a more compact way of expressing\n",
        "# below code... but for simplicity, taken from example for time being\n",
        "def str_to_tokens(sentence):\n",
        "    words = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", sentence).lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')\n",
        "\n",
        "\n",
        "enc_model, dec_model = make_inference_models()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHYIs3pL86Ov",
        "outputId": "47aea7bd-290e-42af-ac7c-ed45958ffc37"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1000200     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'input_5[0][0]',                \n",
            "                                 (None, 200)]                     'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 5001)   1005201     ['lstm_1[2][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,326,201\n",
            "Trainable params: 2,326,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 200)         1000200   \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 200),             320800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,000\n",
            "Trainable params: 1,321,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get 100 random numbers to choose random sentences and calculate BLEU score\n",
        "# note that code must be refactored: it was merged from examples and is \n",
        "# inconsistent now\n",
        "questions = train_df['Question'].to_list()\n",
        "rand_integers = [random.randint(0, len(questions)-1) for i in range(1, 100)]\n",
        "bleu_total = 0\n",
        "\n",
        "\n",
        "for i in rand_integers:\n",
        "    states_values = enc_model.predict(str_to_tokens(questions[i]))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    decoded_translation = decoded_translation[1:]\n",
        "\n",
        "    print(f'Original question: {questions[i]}')\n",
        "    print(f'Predicated answer: {decoded_translation}')\n",
        "\n",
        "    reference_answers = train_df.loc[train_df['Question']==questions[i], 'norm_answer'].to_list()\n",
        "    reference_answers = [answer[8:-7] for answer in reference_answers]\n",
        "\n",
        "\n",
        "    # The following should contain all possible answers, though...\n",
        "    print(f'{reference_answers}')\n",
        "    bleu_score = sentence_bleu(reference_answers, decoded_translation, smoothing_function=SmoothingFunction().method0)\n",
        "    print(f'Bleu score: {bleu_score}\\n')\n",
        "    bleu_total += bleu_score\n",
        "\n",
        "print(f'Bleu average = {bleu_total/len(rand_integers)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QObKQwyVLNzY",
        "outputId": "49bd7ba0-42e5-48d3-b8a1-14597e8f78df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original question: what is melissa and joey about\n",
            "Predicated answer: the american federation of government employees afge is an american labor union created by author\n",
            "['the series follows local politician mel burke melissa joan hart and joe longo joey lawrence whom mel hires to look after her niece and nephew after a ponzi scheme leaves him broke']\n",
            "Bleu score: 0.06620873901049407\n",
            "\n",
            "Original question: how does a steam engine work\n",
            "Predicated answer: steam engines are external combustion engines where the working fluid is separate from the combustion products\n",
            "['a steam engine is a heat engine that performs mechanical work using steam as its working fluid ', 'steam engines are external combustion engines  where the working fluid is separate from the combustion products']\n",
            "Bleu score: 0.9862868634149528\n",
            "\n",
            "Original question: how many stripes on the flag\n",
            "Predicated answer: the 50 stars on the flag represent the 50 states of the united states of america and the 13 stripes represent the thirteen british colonies that declared independence from the kingdom of great britain and became the first states in the union\n",
            "['the 50 stars on the flag represent the 50 states of the united states of america and the 13 stripes represent the thirteen british colonies that declared independence from the kingdom of great britain and became the first states in the union']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what holiday is first weekend of september\n",
            "Predicated answer: labor day is an american federal holiday observed on the first monday in september that celebrates the economic and social contributions of workers\n",
            "['labor day is an american federal holiday observed on the first monday in september that celebrates the economic and social contributions of workers']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: where the streets have no name filming location\n",
            "Predicated answer: the song was notably performed on a los angeles rooftop for the filming of its music video which won a grammy award for best performance music video recently the song has been used by the nfl s baltimore ravens as their entrance song in super bowl xlvii\n",
            "[\"the song was notably performed on a los angeles rooftop for the filming of its music video which won a grammy award for best performance music video recently the song has been used by the nfl's baltimore ravens as their entrance song in super bowl xlvii\"]\n",
            "Bleu score: 0.9900295018584484\n",
            "\n",
            "Original question: how much does a gold bar weigh\n",
            "Predicated answer: the kilobar which is to say 1000 grams in mass is the bar that is more manageable and is used extensively for trading and investment\n",
            "['the standard gold bar held as gold reserves by central banks and traded among bullion dealers is the 400troyounce 124 kg or 4389 ounces good delivery gold bar', 'the kilobar which is to say 1000 grams in mass is the bar that is more manageable and is used extensively for trading and investment']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what is a hosting company on a website\n",
            "Predicated answer: a web hosting service is a type of internet hosting service that allows individuals and organizations to make their website accessible via the world wide web\n",
            "['a web hosting service is a type of internet hosting service that allows individuals and organizations to make their website accessible via the world wide web ']\n",
            "Bleu score: 0.9936508150479583\n",
            "\n",
            "Original question: When was Apple Computer founded\n",
            "Predicated answer: stephen john hadley born february 6 or â february 24 2012 was an american activist and a second author and the network and the of the town of the town in near west\n",
            "['the company was founded on april 1 1976 and incorporated as apple computer inc on january 3 1977']\n",
            "Bleu score: 0.15846397852608118\n",
            "\n",
            "Original question: where are facial sinuses\n",
            "Predicated answer: the pacific source city in normal tires are produced by their origin in the family of light the definition in the human body including the foot thigh and the definition of the\n",
            "['paranasal sinuses are a group of four paired airfilled spaces that surround the nasal cavity  maxillary sinuses  above the eyes  frontal sinuses  between the eyes  ethmoid sinuses  and behind the ethmoids  sphenoid sinuses ']\n",
            "Bleu score: 0.2310012846835158\n",
            "\n",
            "Original question: when Harry met Sally case\n",
            "Predicated answer: the european defeated the show were mister ed a palomino horse who could talk from the series as for the office\n",
            "['the film raises the question can men and women ever just be friends and advances many ideas about relationships that became household concepts such as those of the  girlfriend and the transitional person']\n",
            "Bleu score: 0.14926804592709114\n",
            "\n",
            "Original question: what year did aerosmith i dont want to miss a thing\n",
            "Predicated answer: i don t want to miss a thing is a song performed by american rock band aerosmith for the 1998 film armageddon\n",
            "[\"i don't want to miss a thing is a song performed by american rock band aerosmith for the 1998 film armageddon \"]\n",
            "Bleu score: 0.9768769734531283\n",
            "\n",
            "Original question: when was scooby doo created\n",
            "Predicated answer: kansas or egg was a food best known as the zodiac and his work is the first by and of the\n",
            "['scoobydoo is an american animated cartoon franchise  comprising several animated television series produced from 1969 to the present day']\n",
            "Bleu score: 0.11077763433433084\n",
            "\n",
            "Original question: what does a groundhog look for on groundhog day\n",
            "Predicated answer: according to folklore if it is cloudy when a groundhog emerges from its burrow on this day then spring will come early if it is sunny the groundhog will supposedly see its shadow and retreat back into its burrow and the winter weather will continue for six more weeks\n",
            "['according to folklore if it is cloudy when a groundhog emerges from its burrow on this day then spring will come early if it is sunny the groundhog will supposedly see its shadow and retreat back into its burrow and the winter weather will continue for six more weeks']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: who is E from entourage\n",
            "Predicated answer: eric e\n",
            "['eric e']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what type of batteries are 357 (LR44)\n",
            "Predicated answer: lr44 is the iec designation for an alkaline 15 volt button cell commonly used in small led flashlights digital thermometers calculators calipers watches clocks toys and laser pointers\n",
            "['lr44 is the iec designation for an alkaline 15 volt button cell  commonly used in small led flashlights  digital thermometers  calculators  calipers  watches  clocks  toys and laser pointers ']\n",
            "Bleu score: 0.9288402206579225\n",
            "\n",
            "Original question: what where the most important factors that led to the defeat of the democrates in 1968?\n",
            "Predicated answer: it was a national experience conducted during a year of that included the of civil rights leader martin luther king jr and subsequent race across the nation the of democratic presidential candidate robert f kennedy opposition to the vietnam war across university and violent confrontations between police and at the 1968 democratic national convention as the democratic party split again and again\n",
            "['it was a wrenching national experience conducted during a year of violence that included the assassination of civil rights leader martin luther king jr  and subsequent race riots across the nation the assasination of democratic presidential candidate robert f kennedy  widespread opposition to the vietnam war across university campuses and violent confrontations between police and antiwar protesters at the 1968 democratic national convention as the democratic party split again and again']\n",
            "Bleu score: 0.7789928093781076\n",
            "\n",
            "Original question: what does base jumping stand for\n",
            "Predicated answer: base jumping also sometimes written as base jumping is an activity where participants jump from fixed objects and use a parachute to break their fall\n",
            "['base jumping also sometimes written as base jumping is an activity where participants jump from fixed objects and use a parachute to break their fall', 'base is an acronym that stands for four categories of fixed objects from which one can jump buildings  antennas  spans  bridges  and earth  cliffs ']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what is a Four Lokos\n",
            "Predicated answer: four is a line of beverages originally marketed as energy sold by of chicago illinois\n",
            "['four loko is a line of alcoholic beverages  originally marketed as energy drinks  sold by phusion projects of chicago illinois ']\n",
            "Bleu score: 0.5833434733761258\n",
            "\n",
            "Original question: how was color introduced in film?\n",
            "Predicated answer: the first color cinematography was by means of additive color systems such as the one patented in england by edward raymond turner in 1899 and tested in 1902\n",
            "['the first color cinematography was by means of additive color systems such as the one patented in england by edward raymond turner in 1899 and tested in 1902', 'a simplified additive system was developed by george albert smith and successfully commercialized in 1909 as kinemacolor ']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: where is the human thigh located?\n",
            "Predicated answer: the human is the entire lower or limb of the human body including the foot thigh and even the or region however the definition in human anatomy refers only to the section of the lower limb from the knee to the\n",
            "['the human leg is the entire lower extremity or limb of the human body  including the foot  thigh and even the hip or gluteal region however the precise definition in human anatomy refers only to the section of the lower limb extending from the knee to the ankle ']\n",
            "Bleu score: 0.7549607192187068\n",
            "\n",
            "Original question: what states have legalized prostitution\n",
            "Predicated answer: currently nevada is the only state to allow brothel prostitution the terms of which are stipulated in the nevada revised statutes\n",
            "['currently nevada is the only state to allow brothel prostitution the terms of which are stipulated in the nevada revised statutes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: when can you use a defibulator\n",
            "Predicated answer: is a common treatment for lifethreatening ventricular and ventricular\n",
            "['defibrillation is a common treatment for lifethreatening cardiac dysrhythmias  ventricular fibrillation  and pulseless ventricular tachycardia ']\n",
            "Bleu score: 0.33030338543068294\n",
            "\n",
            "Original question: who owns smirnoff\n",
            "Predicated answer: smirnoff is a brand of owned and produced by the british company\n",
            "['smirnoff is a brand of vodka owned and produced by the british company diageo ']\n",
            "Bleu score: 0.7936210209382516\n",
            "\n",
            "Original question: what does 3g network mean\n",
            "Predicated answer: 3g short for third generation is the third generation of mobile telecommunications technology\n",
            "['3g short for third generation is the third generation of mobile telecommunications technology']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: when was raphael born\n",
            "Predicated answer: april 6 or march 28 â april 6 better known simply as raphael was an italian and architect of the high renaissance\n",
            "['raffaello sanzio da urbino april 6 or march 28 1483 â\\x80\\x93 april 6 1520 better known simply as raphael was an italian painter and architect of the high renaissance ']\n",
            "Bleu score: 0.6567237586927669\n",
            "\n",
            "Original question: when will ie9 be released\n",
            "Predicated answer: it was released to the public on march 14 2011\n",
            "['it was released to the public on march 14 2011']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what people used mayan numeral system\n",
            "Predicated answer: maya numerals are a vigesimal base twenty numeral system used by the precolumbian maya civilization\n",
            "['maya numerals are a vigesimal  base  twenty  numeral system used by the precolumbian maya civilization ']\n",
            "Bleu score: 0.9376366987690617\n",
            "\n",
            "Original question: What political conflicts marked the presidency of William Howard Taft?\n",
            "Predicated answer: taft to further the economic development of nations in latin america and asia through dollar and and restraint in response to revolution in mexico\n",
            "['abroad taft sought to further the economic development of nations in latin america and asia through  dollar diplomacy  and showed decisiveness and restraint in response to revolution in mexico ']\n",
            "Bleu score: 0.7119635258297168\n",
            "\n",
            "Original question: What did Lawrence Joshua Chamberlain do?\n",
            "Predicated answer: joshua lawrence chamberlain september 8 1828 â february 24 1914 born as lawrence joshua chamberlain was an american college professor from the state of maine who volunteered during the american civil war to join the union army\n",
            "['joshua lawrence chamberlain september 8 1828 â\\x80\\x93 february 24 1914 born as lawrence joshua chamberlain was an american college professor from the state of maine  who volunteered during the american civil war to join the union army ']\n",
            "Bleu score: 0.9879603271197344\n",
            "\n",
            "Original question: what classes are considered humanities\n",
            "Predicated answer: the humanities include ancient and modern languages literature philosophy religion and visual and performing arts such as music and theatre\n",
            "['the humanities are academic disciplines that study human culture using methods that are primarily analytical  critical  or speculative  and having a significant historical element as distinguished from the mainly empirical approaches of the natural sciences ', 'the humanities include ancient and modern languages  literature  philosophy  religion  and visual and performing arts such as music and theatre ', 'the humanities that are also regarded as social sciences include history  anthropology  area studies  communication studies  cultural studies  law  economics and linguistics ', 'human disciplines like history  cultural anthropology and psychoanalysis study subject matters to which the experimental method does not apply and they have access instead to the comparative method and comparative research ']\n",
            "Bleu score: 0.9521695602893746\n",
            "\n",
            "Original question: when did pearl harbor get bombed\n",
            "Predicated answer: the attack on pearl harbor called hawaii operation or operation ai by the japanese imperial general headquarters operation z in planning and the battle of pearl harbor was a surprise military strike conducted by the imperial japanese navy against the united states naval base at pearl harbor hawaii on the morning of december 7 1941 december 8 in japan\n",
            "['the attack on pearl harbor called hawaii operation or operation ai by the japanese imperial general headquarters operation z in planning and the battle of pearl harbor was a surprise military strike conducted by the imperial japanese navy against the united states naval base at pearl harbor  hawaii on the morning of december 7 1941 december 8 in japan']\n",
            "Bleu score: 0.9950194415929275\n",
            "\n",
            "Original question: who passed no child left behind\n",
            "Predicated answer: president bush signing the no child left behind act at hamilton in hamilton ohio\n",
            "['president bush signing the no child left behind act at hamilton hs in hamilton ohio ']\n",
            "Bleu score: 0.941948027636413\n",
            "\n",
            "Original question: what is the official language of america?\n",
            "Predicated answer: the most commonly used language is english\n",
            "['the most commonly used language is english ']\n",
            "Bleu score: 0.9764716866522433\n",
            "\n",
            "Original question: what is spelt flour\n",
            "Predicated answer: spelt also known as wheat or wheat is an ancient species of wheat from the fifth bc\n",
            "['spelt also known as dinkel wheat or hulled wheat is an ancient species of wheat from the fifth millennium bc', 'it is a hexaploid wheat which means it has six sets of chromosomes']\n",
            "Bleu score: 0.9714888693954227\n",
            "\n",
            "Original question: what countries are in cono sur\n",
            "Predicated answer: in the narrowest sense it only covers argentina chile and uruguay bounded on the north by the states of brazil paraguay bolivia and peru on the west by the pacific ocean and south to the junction between the pacific and atlantic oceans which it is the closest continental area of antarctica 1000 km\n",
            "['although geographically this includes southern and part of southeast  sã£o paulo  of brazil  in terms of political geography the southern cone has traditionally comprised argentina  chile  paraguay  and uruguay ', 'in the narrowest sense it only covers argentina  chile and uruguay  bounded on the north by the states of brazil paraguay bolivia and peru on the west by the pacific ocean and south to the junction between the pacific and atlantic oceans which it is the closest continental area of antarctica 1000 km']\n",
            "Bleu score: 0.9882502207463585\n",
            "\n",
            "Original question: where are Giant Panda Bears found?\n",
            "Predicated answer: the giant panda lives in a few mountain ranges in central china mainly in province but also in the and\n",
            "['the giant panda lives in a few mountain ranges in central china mainly in sichuan province but also in the shaanxi and gansu provinces']\n",
            "Bleu score: 0.7233001564503565\n",
            "\n",
            "Original question: How Do You Get Hepatitis C\n",
            "Predicated answer: hcv is spread primarily by bloodtoblood contact associated with intravenous drug use poorly sterilized medical equipment and transfusions\n",
            "['hcv is spread primarily by bloodtoblood contact associated with intravenous drug use  poorly sterilized medical equipment and transfusions ']\n",
            "Bleu score: 0.9799862342410317\n",
            "\n",
            "Original question: When did F15s first fly\n",
            "Predicated answer: the first in july 1972 and service in 1976\n",
            "['the eagle first flew in july 1972 and entered service in 1976']\n",
            "Bleu score: 0.6152271064651814\n",
            "\n",
            "Original question: what is mincemeat made of\n",
            "Predicated answer: mincemeat is a mixture of dried fruit distilled and and sometimes beef beef or\n",
            "['mincemeat is a mixture of chopped dried fruit  distilled spirits and spices  and sometimes beef suet  beef  or venison ']\n",
            "Bleu score: 0.5544443172473237\n",
            "\n",
            "Original question: when was raphael born\n",
            "Predicated answer: april 6 or march 28 â april 6 better known simply as raphael was an italian and architect of the high renaissance\n",
            "['raffaello sanzio da urbino april 6 or march 28 1483 â\\x80\\x93 april 6 1520 better known simply as raphael was an italian painter and architect of the high renaissance ']\n",
            "Bleu score: 0.6567237586927669\n",
            "\n",
            "Original question: what county is northville mi\n",
            "Predicated answer: northville is an affluent city located in and divided by oakland and wayne counties in the us state of michigan\n",
            "['northville is an affluent city located in and divided by oakland and wayne counties in the us state of michigan ', 'most of the city is in oakland county and is surrounded by the city of novi ']\n",
            "Bleu score: 0.9910314505214005\n",
            "\n",
            "Original question: what county is jennings, la\n",
            "Predicated answer: jennings is a small city in and the parish seat of jefferson davis parish louisiana united states near lake charles\n",
            "['jennings is a small city in and the parish seat of jefferson davis parish  louisiana  united states  near lake charles ']\n",
            "Bleu score: 0.946225452709504\n",
            "\n",
            "Original question: what makes a dwarf planet\n",
            "Predicated answer: more the international union defines a dwarf planet as a body in direct orbit of the sun that is massive for its shape to be controlled by gravitation but that unlike a planet has not its orbital region of other objects\n",
            "['a dwarf planet is a planetarymass object that is neither a planet nor a satellite ', 'more explicitly the international astronomical union iau defines a dwarf planet as a celestial body in direct orbit of the sun that is massive enough for its shape to be controlled by gravitation  but that unlike a planet has not cleared its orbital region of other objects']\n",
            "Bleu score: 0.7659083869754603\n",
            "\n",
            "Original question: what is spelt flour\n",
            "Predicated answer: spelt also known as wheat or wheat is an ancient species of wheat from the fifth bc\n",
            "['spelt also known as dinkel wheat or hulled wheat is an ancient species of wheat from the fifth millennium bc', 'it is a hexaploid wheat which means it has six sets of chromosomes']\n",
            "Bleu score: 0.9714888693954227\n",
            "\n",
            "Original question: what did chaucer do\n",
            "Predicated answer: while he achieved fame during his lifetime as an author philosopher alchemist and astronomer composing a scientific treatise on the astrolabe for his ten yearold son lewis chaucer also maintained an active career in the civil service as a bureaucrat courtier and diplomat\n",
            "['while he achieved fame during his lifetime as an author philosopher alchemist and astronomer  composing a scientific treatise on the astrolabe for his ten yearold son lewis chaucer also maintained an active career in the civil service as a bureaucrat courtier and diplomat', 'chaucer is a crucial figure in developing the legitimacy of the vernacular  middle english  at a time when the dominant literary languages in england were french and latin']\n",
            "Bleu score: 0.9935272345776406\n",
            "\n",
            "Original question: what is Polyester in packaging PET\n",
            "Predicated answer: polyethylene terephthalate sometimes written polyethylene terephthalate commonly abbreviated pet or the petp or petp is a of the polyester family and is used in synthetic beverage food and other liquid applications and engineering often in with glass fiber\n",
            "['polyethylene terephthalate sometimes written polyethylene terephthalate commonly abbreviated pet pete or the obsolete petp or petp is a thermoplastic polymer resin of the polyester family and is used in synthetic fibers  beverage food and other liquid containers  thermoforming applications and engineering resins often in combination with glass fiber']\n",
            "Bleu score: 0.6782683781078808\n",
            "\n",
            "Original question: who created the tourbillon movement?\n",
            "Predicated answer: developed around by the from an earlier idea by the english john arnold a tourbillon aims to the effects of gravity by the escapement and balance wheel in a to the effect of gravity when the thus the escapement is in a certain position\n",
            "['developed around 1795 by the frenchswiss watchmaker abrahamlouis breguet from an earlier idea by the english chronometer maker john arnold  a tourbillon aims to counter the effects of gravity by mounting the escapement and balance wheel in a rotating cage to negate the effect of gravity when the timepiece thus the escapement is stuck in a certain position']\n",
            "Bleu score: 0.5794081137663009\n",
            "\n",
            "Original question: how fire extinguisher works\n",
            "Predicated answer: cartridgeoperated extinguishers contain the expellant gas in a separate cartridge that is punctured prior to discharge exposing the propellant to the extinguishing agent\n",
            "['cartridgeoperated extinguishers contain the expellant gas in a separate cartridge that is punctured prior to discharge exposing the propellant to the extinguishing agent']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what is a Four Lokos\n",
            "Predicated answer: four is a line of beverages originally marketed as energy sold by of chicago illinois\n",
            "['four loko is a line of alcoholic beverages  originally marketed as energy drinks  sold by phusion projects of chicago illinois ']\n",
            "Bleu score: 0.5833434733761258\n",
            "\n",
            "Original question: who is the guy in the wheelchair who is smart\n",
            "Predicated answer: professor stephen are a song written by medicine that originally performed by the first monday in january 27 1991 following the late 19th century\n",
            "['professor stephen hawking  known for being a theoretical physicist  has appeared in many works of popular culture ']\n",
            "Bleu score: 0.3044492209802527\n",
            "\n",
            "Original question: what does it mean to be a commonwealth state\n",
            "Predicated answer: commonwealth is a traditional english term for a political community founded for the common good\n",
            "['commonwealth is a traditional english term for a political community founded for the common good']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What causes rogue waves\n",
            "Predicated answer: rogue waves seem not to have a single distinct cause but occur where physical factors such as high winds and strong currents cause waves to merge to create a single exceptionally large wave\n",
            "['rogue waves seem not to have a single distinct cause but occur where physical factors such as high winds and strong currents cause waves to merge to create a single exceptionally large wave']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what was nixon accused of\n",
            "Predicated answer: the watergate scandal was a political scandal that occurred in the united states in the 1970s as a result of the june 17 1972 at the democratic national committee headquarters at the watergate office complex in washington dc and the nixon administration s of its\n",
            "[\"the watergate scandal was a political scandal that occurred in the united states in the 1970s as a result of the june 17 1972 breakin at the democratic national committee headquarters at the watergate office complex in washington dc and the nixon administration's attempted coverup of its involvement\", 'the scandal eventually led to the resignation of richard nixon  the president of the united states on august 9 1974 â\\x80\\x94 the only resignation of a us president']\n",
            "Bleu score: 0.8566216911101627\n",
            "\n",
            "Original question: when was andy griffith born\n",
            "Predicated answer: andy samuel griffith june 1 â july 3 2012 was an american actor television producer grammy award winning singer and writer\n",
            "['andy samuel griffith june 1 1926 â\\x80\\x93 july 3 2012 was an american actor television producer grammy award winning southerngospel singer and writer']\n",
            "Bleu score: 0.8439817332850859\n",
            "\n",
            "Original question: who is elizabeth from general hospital who are the boys fathers\n",
            "Predicated answer: elizabeth formerly and is a fictional character on the abc general hospital\n",
            "['elizabeth imogene webber formerly lansing and spencer is a fictional character on the abc daytime soap opera general hospital ']\n",
            "Bleu score: 0.4850351128424776\n",
            "\n",
            "Original question: what is in milk\n",
            "Predicated answer: early milk contains which carries the s to the baby and can reduce the risk of many in the baby\n",
            "['milk is a white liquid produced by the mammary glands of mammals ', \"early lactation milk contains colostrum  which carries the mother's antibodies to the baby and can reduce the risk of many diseases in the baby\"]\n",
            "Bleu score: 0.9586526362495928\n",
            "\n",
            "Original question: WHAT COUNTRY IS MEXICO IN\n",
            "Predicated answer: mexico officially the united mexican states is a federal constitutional republic in north america\n",
            "['mexico    officially the united mexican states  is a federal constitutional republic in north america']\n",
            "Bleu score: 0.9441901141560768\n",
            "\n",
            "Original question: when can you use a defibulator\n",
            "Predicated answer: is a common treatment for lifethreatening ventricular and ventricular\n",
            "['defibrillation is a common treatment for lifethreatening cardiac dysrhythmias  ventricular fibrillation  and pulseless ventricular tachycardia ']\n",
            "Bleu score: 0.33030338543068294\n",
            "\n",
            "Original question: what cheese is made from goat's milk\n",
            "Predicated answer: goat is a natural protein fibre in the united kingdom loyal to the moon or partially shortened to just pci is an area by a machine\n",
            "['goat cheese or chã¨vre from the french word for goat is cheese made out of the milk of goats ']\n",
            "Bleu score: 0.21101837339820984\n",
            "\n",
            "Original question: What causes rogue waves\n",
            "Predicated answer: rogue waves seem not to have a single distinct cause but occur where physical factors such as high winds and strong currents cause waves to merge to create a single exceptionally large wave\n",
            "['rogue waves seem not to have a single distinct cause but occur where physical factors such as high winds and strong currents cause waves to merge to create a single exceptionally large wave']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what county is catonsville md in\n",
            "Predicated answer: catonsville is a censusdesignated place cdp in baltimore county maryland united states\n",
            "['catonsville is a censusdesignated place cdp in baltimore county  maryland  united states']\n",
            "Bleu score: 0.9592261717340278\n",
            "\n",
            "Original question: what are american people of japanese descent called\n",
            "Predicated answer: japanese americans have historically been among the three largest american communities but in recent decades it has become the sixth largest group at roughly including those of or\n",
            "['are american people of japanese heritage ', 'japanese americans have historically been among the three largest asian american communities but in recent decades it has become the sixth largest group at roughly 1304286 including those of mixedrace or mixedethnicity']\n",
            "Bleu score: 0.7961854488991283\n",
            "\n",
            "Original question: who wrote serenity prayer\n",
            "Predicated answer: the serenity prayer is the common name for an originally prayer by the american\n",
            "['the serenity prayer is the common name for an originally untitled prayer by the american theologian reinhold niebuhr 1892â\\x80\\x931971']\n",
            "Bleu score: 0.5324915517836998\n",
            "\n",
            "Original question: who made hubble telescope\n",
            "Predicated answer: the was built by the united states space agency with contributions from the european space agency and is operated by the space telescope science institute\n",
            "['the hst was built by the united states space agency nasa  with contributions from the european space agency  and is operated by the space telescope science institute ']\n",
            "Bleu score: 0.9111550895197141\n",
            "\n",
            "Original question: where is the human thigh located?\n",
            "Predicated answer: the human is the entire lower or limb of the human body including the foot thigh and even the or region however the definition in human anatomy refers only to the section of the lower limb from the knee to the\n",
            "['the human leg is the entire lower extremity or limb of the human body  including the foot  thigh and even the hip or gluteal region however the precise definition in human anatomy refers only to the section of the lower limb extending from the knee to the ankle ']\n",
            "Bleu score: 0.7549607192187068\n",
            "\n",
            "Original question: Who Started the Mormon Church\n",
            "Predicated answer: mormons are a religious and cultural group related to mormonism the principal branch of the latter day saint movement of restorationist christianity which began with the visions of joseph smith in upstate new york during the 1820s\n",
            "['mormons  are a religious and cultural group related to mormonism  the principal branch of the latter day saint movement of restorationist christianity  which began with the visions of joseph smith in upstate new york during the 1820s']\n",
            "Bleu score: 0.9772120447084626\n",
            "\n",
            "Original question: what is melissa and joey about\n",
            "Predicated answer: the american federation of government employees afge is an american labor union created by author\n",
            "['the series follows local politician mel burke melissa joan hart and joe longo joey lawrence whom mel hires to look after her niece and nephew after a ponzi scheme leaves him broke']\n",
            "Bleu score: 0.06620873901049407\n",
            "\n",
            "Original question: what causes thunder sound\n",
            "Predicated answer: in turn this expansion of air creates a sonic shock wave similar to a sonic boom which produces the sound of thunder often referred to as a clap crack or peal of thunder\n",
            "['thunder is the sound caused by lightning ', 'in turn this expansion of air creates a sonic shock wave similar to a sonic boom  which produces the sound of thunder often referred to as a clap crack or peal of thunder']\n",
            "Bleu score: 0.9896053953063927\n",
            "\n",
            "Original question: what is an array in programming\n",
            "Predicated answer: in computer science array programming languages also known as vector or multidimensional languages generalize operations on scalars to apply transparently to vectors matrices and higher dimensional arrays\n",
            "['in computer science  array programming languages also known as vector or multidimensional languages generalize operations on scalars to apply transparently to vectors  matrices  and higher dimensional arrays', 'array programming primitives concisely express broad ideas about data manipulation']\n",
            "Bleu score: 0.9743127406681618\n",
            "\n",
            "Original question: what are superannuation contributions?\n",
            "Predicated answer: superannuation in australia refers to the arrangements which people make in australia to have funds available for them in retirement\n",
            "['superannuation in australia refers to the arrangements which people make in australia to have funds available for them in retirement ']\n",
            "Bleu score: 0.9924528661479256\n",
            "\n",
            "Original question: when did lucy stone died\n",
            "Predicated answer: lucy stone august 13 â october 19 was a american abolitionist and and a and promoting rights for women\n",
            "['lucy stone august 13 1818 â\\x80\\x93 october 19 1893 was a prominent american abolitionist and suffragist  and a vocal advocate and organizer promoting rights for women ']\n",
            "Bleu score: 0.5463641960192525\n",
            "\n",
            "Original question: What Causes Brain Freeze\n",
            "Predicated answer: it is caused by having something cold touch the roof of the mouth palate and is believed to result from a nerve response causing rapid constriction and swelling of blood vessels or a referring of pain from the roof of the mouth to the head\n",
            "['it is caused by having something cold touch the roof of the mouth  palate  and is believed to result from a nerve response causing rapid constriction and swelling of blood vessels or a  referring  of pain from the roof of the mouth to the head']\n",
            "Bleu score: 0.9708208117926364\n",
            "\n",
            "Original question: where were the Winter Olympics in 2006\n",
            "Predicated answer: the 2006 winter olympics officially known as the winter games was a winter event which was celebrated in italy from february 10 2006 through february 26 2006\n",
            "['the 2006 winter olympics officially known as the xx olympic winter games was a winter multisport event which was celebrated in turin  italy from february 10 2006 through february 26 2006']\n",
            "Bleu score: 0.8191118733368199\n",
            "\n",
            "Original question: what is metal music about\n",
            "Predicated answer: with roots in rock and psychedelic rock the that created heavy metal developed a thick massive sound characterized by highly extended guitar and overall\n",
            "['with roots in blues rock and psychedelic rock  the bands that created heavy metal developed a thick massive sound characterized by highly amplified distortion  extended guitar solos emphatic beats and overall loudness', 'heavy metal lyrics and performance styles are generally associated with masculinity and machismo ']\n",
            "Bleu score: 0.9744876033785052\n",
            "\n",
            "Original question: where is the island New Guinea?\n",
            "Predicated answer: located in the pacific ocean it lies geographically to the east of the archipelago with which it is sometimes included as part of a greater archipelago\n",
            "['located in the southwest pacific ocean  it lies geographically to the east of the malay archipelago  with which it is sometimes included as part of a greater indoaustralian archipelago ']\n",
            "Bleu score: 0.7778757579888047\n",
            "\n",
            "Original question: what are grits made from\n",
            "Predicated answer: modern grits are commonly made of corn known as\n",
            "['modern grits are commonly made of alkalitreated corn known as hominy ']\n",
            "Bleu score: 0.6154920041547792\n",
            "\n",
            "Original question: what is reagan known for\n",
            "Predicated answer: victory in the cold war led to a world with the us as the world s sole\n",
            "['domestically the administration favored reducing government programs and introduced the largest acrosstheboard tax cuts in american history', \"victory in the cold war led to a unipolar world with the us as the world's sole superpower\", 'furthermore says henry the consensus viewpoint agrees that he revived faith in the presidency and american selfconfidence and contributed critically to ending the cold war ']\n",
            "Bleu score: 0.7230151302712717\n",
            "\n",
            "Original question: what composer used sound mass\n",
            "Predicated answer: a very early example is the opening of jeanfã©ry rebel s ballet les elã©mens 1737â38 where chaos is represented by a gradually cumulating orchestral cluster of all seven notes of the d minor scale henck 2004 pp 52â54\n",
            "[\"composers and works include barbara kolb  pauline oliveros ' sound patterns for chorus 1961 norma beecroft 's from dreams of brass for chorus 1963â\\x80\\x931964 and nancy van de vate \", \"a very early example is the opening of jeanfã©ry rebel 's ballet les elã©mens 1737â\\x80\\x9338 where chaos is represented by a gradually cumulating orchestral cluster of all seven notes of the d minor scale henck 2004 pp 52â\\x80\\x9354\", \"a later example is the third movement of ruth crawford seeger 's string quartet 1931 nonesuch h71280 while more recently phill niblock 's multiple drone based music serves as an example\", 'the use of chords approaching timbres begins with debussy and edgard varã¨se often carefully scored individual instrumental parts so that they would fuse into one ensemble timbre or sound mass erickson 1975 pp 18 and 21', \"other examples include european textural compositions of the fifties and sixties such as krzysztof penderecki 's threnody to the victims of hiroshima 1959 and gyã¶rgy ligeti 's works featuring micropolyphony in works like atmosphã¨res 1961 and his requiem 196365\", 'other composers with works using this technique include henryk gã³recki  karel husa  witold lutoså\\x82awski  kazimierz serocki  and steven stucky ', 'sound mass techniques also appear in the music of george crumb anon nd']\n",
            "Bleu score: 0.9942321995929908\n",
            "\n",
            "Original question: what year did aerosmith i dont want to miss a thing\n",
            "Predicated answer: i don t want to miss a thing is a song performed by american rock band aerosmith for the 1998 film armageddon\n",
            "[\"i don't want to miss a thing is a song performed by american rock band aerosmith for the 1998 film armageddon \"]\n",
            "Bleu score: 0.9768769734531283\n",
            "\n",
            "Original question: what are anti inflammatories\n",
            "Predicated answer: they referred to as speedway is a motorcycle sport involving four and sometimes up to six over four of an circuit\n",
            "['antiinflammatory refers to the property of a substance or treatment that reduces inflammation ']\n",
            "Bleu score: 0.22144739130031857\n",
            "\n",
            "Original question: what is melissa and joey about\n",
            "Predicated answer: the american federation of government employees afge is an american labor union created by author\n",
            "['the series follows local politician mel burke melissa joan hart and joe longo joey lawrence whom mel hires to look after her niece and nephew after a ponzi scheme leaves him broke']\n",
            "Bleu score: 0.06620873901049407\n",
            "\n",
            "Original question: how much total wealth in USA\n",
            "Predicated answer: including human capital such as skills the united nations estimated the total wealth of the united states in 2008 to be 118 trillion\n",
            "['including human capital such as skills the united nations estimated the total wealth of the united states in 2008 to be $118 trillion']\n",
            "Bleu score: 0.9809339541107623\n",
            "\n",
            "Original question: What is caused by the human immunodeficiency virus?\n",
            "Predicated answer: human immunodeficiency virus is a that causes acquired immunodeficiency syndrome aids a condition in humans in which of the immune system allows lifethreatening infections and to\n",
            "['human immunodeficiency virus hiv is a lentivirus slowly replicating retrovirus  that causes acquired immunodeficiency syndrome aids a condition in humans in which progressive failure of the immune system allows lifethreatening opportunistic infections and cancers to thrive']\n",
            "Bleu score: 0.5737146683002249\n",
            "\n",
            "Original question: what are warehouse spreadsheets used for\n",
            "Predicated answer: the data stored in the warehouse are uploaded from the operational systems such as marketing sales etc shown in the figure to the right\n",
            "['the data stored in the warehouse are uploaded from the operational systems such as marketing sales etc shown in the figure to the right', 'the data may pass through an operational data store for additional operations before they are used in the dw for reporting', 'the access layer helps users retrieve data']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: how many presidents have been assassinated\n",
            "Predicated answer: four sitting presidents have been killed abraham lincoln the 16th president james a garfield the 20th president william mckinley the 25th president and john f kennedy the 35th president\n",
            "['four sitting presidents have been killed abraham lincoln the 16th president james a garfield the 20th president william mckinley the 25th president and john f kennedy the 35th president']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what is the lowest temperature ever recorded in antarctica\n",
            "Predicated answer: antarctica has the lowest naturally occurring temperature ever recorded on the ground on earth â°c at station\n",
            "['antarctica has the lowest naturally occurring temperature ever recorded on the ground on earth â\\x88\\x92892 â°c â\\x88\\x921286 â°f at vostok station ']\n",
            "Bleu score: 0.7675872022469018\n",
            "\n",
            "Original question: what is spelt flour\n",
            "Predicated answer: spelt also known as wheat or wheat is an ancient species of wheat from the fifth bc\n",
            "['spelt also known as dinkel wheat or hulled wheat is an ancient species of wheat from the fifth millennium bc', 'it is a hexaploid wheat which means it has six sets of chromosomes']\n",
            "Bleu score: 0.9714888693954227\n",
            "\n",
            "Original question: what did sparta do around 650 bc\n",
            "Predicated answer: around 650 bc it rose to become the dominant military landpower in ancient greece\n",
            "['around 650 bc it rose to become the dominant military landpower in ancient greece']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: what does add my two cents mean\n",
            "Predicated answer: my two cents 2â¢ and its longer version put my two cents in is an united states us idiomatic expression taken from the original english idiom expression to put in my two pennies worth or my tuppence worth\n",
            "['my two cents 2â¢ and its longer version put my two cents in is an united states us idiomatic expression taken from the original english idiom expression to put in my two pennies worth or my tuppence worth']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: who is norah jones parents\n",
            "Predicated answer: she is the of indian player and jones\n",
            "['she is the daughter of indian sitar player ravi shankar and sue jones']\n",
            "Bleu score: 0.3887188998051037\n",
            "\n",
            "Original question: what composer used sound mass\n",
            "Predicated answer: a very early example is the opening of jeanfã©ry rebel s ballet les elã©mens 1737â38 where chaos is represented by a gradually cumulating orchestral cluster of all seven notes of the d minor scale henck 2004 pp 52â54\n",
            "[\"composers and works include barbara kolb  pauline oliveros ' sound patterns for chorus 1961 norma beecroft 's from dreams of brass for chorus 1963â\\x80\\x931964 and nancy van de vate \", \"a very early example is the opening of jeanfã©ry rebel 's ballet les elã©mens 1737â\\x80\\x9338 where chaos is represented by a gradually cumulating orchestral cluster of all seven notes of the d minor scale henck 2004 pp 52â\\x80\\x9354\", \"a later example is the third movement of ruth crawford seeger 's string quartet 1931 nonesuch h71280 while more recently phill niblock 's multiple drone based music serves as an example\", 'the use of chords approaching timbres begins with debussy and edgard varã¨se often carefully scored individual instrumental parts so that they would fuse into one ensemble timbre or sound mass erickson 1975 pp 18 and 21', \"other examples include european textural compositions of the fifties and sixties such as krzysztof penderecki 's threnody to the victims of hiroshima 1959 and gyã¶rgy ligeti 's works featuring micropolyphony in works like atmosphã¨res 1961 and his requiem 196365\", 'other composers with works using this technique include henryk gã³recki  karel husa  witold lutoså\\x82awski  kazimierz serocki  and steven stucky ', 'sound mass techniques also appear in the music of george crumb anon nd']\n",
            "Bleu score: 0.9942321995929908\n",
            "\n",
            "Original question: what is a synthetic conduit\n",
            "Predicated answer: a nerve conduit also referred to as an artificial nerve conduit or artificial nerve as to an is an artificial means of guiding to facilitate nerve and is one of several clinical for nerve\n",
            "['a nerve guidance conduit also referred to as an artificial nerve conduit or artificial nerve graft as opposed to an autograft  is an artificial means of guiding axonal regrowth to facilitate nerve regeneration and is one of several clinical treatments for nerve injuries ']\n",
            "Bleu score: 0.6214135876652004\n",
            "\n",
            "Original question: what are a and r reps\n",
            "Predicated answer: artists and a r is the division of a record label or music company that is responsible for talent and the artistic development of recording artists andor\n",
            "['artists and repertoire a&r is the division of a record label or music publishing company that is responsible for talent scouting and overseeing the artistic development of recording artists andor songwriters']\n",
            "Bleu score: 0.6801116371349141\n",
            "\n",
            "Original question: what is the official language of america?\n",
            "Predicated answer: the most commonly used language is english\n",
            "['the most commonly used language is english ']\n",
            "Bleu score: 0.9764716866522433\n",
            "\n",
            "Original question: how long was frank sinatra famous\n",
            "Predicated answer: beginning his musical career in the swing era with harry james and tommy dorsey sinatra found unprecedented success as a solo artist from the early to mid1940s after being signed to columbia records in 1943\n",
            "['beginning his musical career in the swing era with harry james and tommy dorsey  sinatra found unprecedented success as a solo artist from the early to mid1940s after being signed to columbia records in 1943']\n",
            "Bleu score: 0.9914783762592896\n",
            "\n",
            "Original question: who discovered the 2 moons of mars,Phobos and Deimos\n",
            "Predicated answer: both were discovered in by carolina and republican candidate richard leave been 25 2005\n",
            "['both satellites were discovered in 1877 by asaph hall and are named after the characters phobos panicfear and deimos terrordread who in greek mythology  accompanied their father ares  god of war into battle']\n",
            "Bleu score: 0.12450938625458524\n",
            "\n",
            "Original question: what is a medallion guarantee\n",
            "Predicated answer: they also the liability of the transfer agent who accepts the\n",
            "['it is a guarantee by the transferring financial institution that the signature is genuine and the financial institution accepts liability for any forgery', 'they also limit the liability of the transfer agent who accepts the certificates']\n",
            "Bleu score: 0.7228729140568715\n",
            "\n",
            "Original question: when was the patriot act enacted\n",
            "Predicated answer: the usa patriot act of 2001 is an act of the us congress that was signed into law by president george w bush on october 26 2001\n",
            "['the usa patriot act of 2001 is an act of the us congress that was signed into law by president george w bush on october 26 2001']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: who is norah jones parents\n",
            "Predicated answer: she is the of indian player and jones\n",
            "['she is the daughter of indian sitar player ravi shankar and sue jones']\n",
            "Bleu score: 0.3887188998051037\n",
            "\n",
            "Bleu average = 0.7752261465710513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input('Ask me something, or enter \\'end\\' to stop: ')\n",
        "    if question == 'end':\n",
        "        break\n",
        "    states_values = enc_model.predict(str_to_tokens(question))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "metadata": {
        "id": "KAsbo2TRkAsh",
        "outputId": "8e97abb2-33f9-4229-e7b9-537cf37dde3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask me something, or enter 'end' to stop: how are you doing today?\n",
            " sedimentary rocks are types of rock that are formed by the deposition of material at the earth s surface and within bodies of water\n",
            "Ask me something, or enter 'end' to stop: How are epithelial tissues joined together\n",
            " the term may be applied to someone who are actually a foreigner or it can denote a strong association or assimilation into foreign particularly us society and culture\n",
            "Ask me something, or enter 'end' to stop: how big is bmc software in houston, tx\n",
            " in america or is a neighborhood in the state of ice hockey that it through a leader in which the confederacy through the first day\n",
            "Ask me something, or enter 'end' to stop: How much is US National Debt limit?\n",
            " shem säm säm name s service is the world s last in world s largest producer of the coastal city and is in the of they also the third version of the murder of the united states\n",
            "Ask me something, or enter 'end' to stop: how much is an adult film actor paid\n",
            " shem right is the common word as a s technology for the united states or to mass urine is a christian clank a population\n",
            "Ask me something, or enter 'end' to stop: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ny-x6HP6wrg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}