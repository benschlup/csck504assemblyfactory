{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_2_sequence_model_Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschlup/csck504assemblyfactory/blob/main/QA_Sequence_2_sequence_model_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Translation using a RNN\n",
        "\n",
        "In this tutorial we will learn how to RNNs to build Sequence-2-Sequence (seq-2-seq) model for Neural machine Translation. We will build LSTM-based seq-2-seq model for translating German sentences into English sentences. "
      ],
      "metadata": {
        "id": "Yb_n81X5rsmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us import the necessary libraries\n",
        "\n",
        "1. Pytorch for using LSTM layer\n",
        "2. Spacy for text processing"
      ],
      "metadata": {
        "id": "GySNhZA2rjLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gtM2tDZIrR29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas\n",
        "import spacy\n",
        "import urllib\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.de import German\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from tqdm import tqdm_notebook\n",
        "import random\n",
        "from collections import Counter\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the GPU is visible to our runtime\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "metadata": {
        "id": "fVHLHDXRCDu2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "urllib.request.urlretrieve(\"https://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\", \"Question_Answer_Dataset_v1.2.tar.gz\")"
      ],
      "metadata": {
        "id": "aP_yFOBnKd8y",
        "outputId": "c1d82814-c5bb-44e8-c162-e236afca0f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Question_Answer_Dataset_v1.2.tar.gz',\n",
              " <http.client.HTTPMessage at 0x7fa62b678350>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files\n",
        "file = tarfile.open('Question_Answer_Dataset_v1.2.tar.gz')\n",
        "file.extractall('.')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "TRkjs0C8KnHd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import questions and answers from all courses in Spring 2008, 2009 and 2010 respectively\n",
        "qa_df = pd.DataFrame()\n",
        "for course in ['S08', 'S09', 'S10']:\n",
        "    print(f'Reading questions and answers from course {course}')\n",
        "    course_qa_df = pd.read_csv( f'./Question_Answer_Dataset_v1.2/{course}/question_answer_pairs.txt', sep='\\t', encoding='ISO-8859-1')\n",
        "    course_qa_df['course'] = course\n",
        "    qa_df = pd.concat([qa_df, course_qa_df])"
      ],
      "metadata": {
        "id": "Aw4QGZkvK4Ml",
        "outputId": "b09b8313-5374-474e-f5d6-09630b35332f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading questions and answers from course S08\n",
            "Reading questions and answers from course S09\n",
            "Reading questions and answers from course S10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove lines not having answers (or not even having questions, in some cases...):\n",
        "qa_df = qa_df[qa_df['Answer'].notna()]"
      ],
      "metadata": {
        "id": "RY7VF6eGNUbj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data():\n",
        "  # get english/french sentence pairs\n",
        "  en = qa_df['Question'].to_list()\n",
        "  de = qa_df['Answer'].to_list()\n",
        "  \n",
        "  # We'll be using the spaCy's English and German tokenizers\n",
        "  spacy_en = English()\n",
        "  spacy_de = German()\n",
        "  \n",
        "  en_words = Counter()\n",
        "  de_words = Counter()\n",
        "  en_inputs = []\n",
        "  de_inputs = []\n",
        "  \n",
        "  # Tokenizing the English and German sentences and creating our word banks for both languages\n",
        "  for i in range(len(en)):\n",
        "      en_tokens = spacy_en(en[i])\n",
        "      de_tokens = spacy_de(de[i])\n",
        "      if len(en_tokens)==0 or len(de_tokens)==0:\n",
        "          continue\n",
        "      for token in en_tokens:\n",
        "          en_words.update([token.text.lower()])\n",
        "      en_inputs.append([token.text.lower() for token in en_tokens] + ['_EOS'])\n",
        "      for token in de_tokens:\n",
        "          de_words.update([token.text.lower()])\n",
        "      de_inputs.append([token.text.lower() for token in de_tokens] + ['_EOS'])\n",
        "    \n",
        "  # Assigning an index to each word token, including the Start Of String(SOS), End Of String(EOS) and Unknown(UNK) tokens\n",
        "  en_words = ['_SOS','_EOS','_UNK'] + sorted(en_words,key=en_words.get,reverse=True)\n",
        "  en_w2i = {o:i for i,o in enumerate(en_words)}\n",
        "  en_i2w = {i:o for i,o in enumerate(en_words)}\n",
        "  de_words = ['_SOS','_EOS','_UNK'] + sorted(de_words,key=de_words.get,reverse=True)\n",
        "  de_w2i = {o:i for i,o in enumerate(de_words)}\n",
        "  de_i2w = {i:o for i,o in enumerate(de_words)}\n",
        "  \n",
        "  # Converting our English and German sentences to their token indexes\n",
        "  for i in range(len(en_inputs)):\n",
        "      en_sentence = en_inputs[i]\n",
        "      de_sentence = de_inputs[i]\n",
        "      en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
        "      de_inputs[i] = [de_w2i[word] for word in de_sentence]\n",
        "  \n",
        "  return en_words, de_words, en_w2i, en_i2w, de_w2i, de_i2w, en_inputs, de_inputs\n"
      ],
      "metadata": {
        "id": "1HYjRSY78tgM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_words, de_words, en_w2i, en_i2w, de_w2i, de_i2w, en_inputs, de_inputs = prepare_data()\n",
        "\n",
        "en_inputs[0], de_inputs[0]"
      ],
      "metadata": {
        "id": "Fljz0IuY-qNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0792c1e-4843-4606-aff8-5ca0a91d5ac3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([10, 737, 93, 4, 1480, 68, 5, 4, 130, 134, 3, 1], [3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write our Encoder Class"
      ],
      "metadata": {
        "id": "Y9WWqnNO6Jap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, vocab_len, input_dim, hidden_dim, n_layers=1, drop_prob=0):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        " \n",
        "    self.embedding = nn.Embedding(vocab_len, input_dim)\n",
        "    self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, \n",
        "                        dropout=drop_prob, batch_first=True)\n",
        " \n",
        "  def forward(self, inputs, encoder_state_vector, encoder_cell_vector):\n",
        "    embedded = self.embedding(inputs)\n",
        "    # Pass the embedded word vectors into LSTM and return all outputs\n",
        "    output, hidden = self.lstm(embedded, (encoder_state_vector, encoder_cell_vector))\n",
        "    return output, hidden\n",
        " \n",
        "  def init_hidden(self, batch_size=1):\n",
        "    return (torch.zeros(self.n_layers, batch_size, \n",
        "                        self.hidden_dim),\n",
        "            torch.zeros(self.n_layers, batch_size, \n",
        "                        self.hidden_dim))\n"
      ],
      "metadata": {
        "id": "uUiYFmormj2E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write our Decoder class"
      ],
      "metadata": {
        "id": "ounElB9y8FuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_vocab_len, n_layers=1, drop_prob=0.1):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_vocab_len = output_vocab_len\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_prob = drop_prob\n",
        "    self.input_dim = input_dim\n",
        " \n",
        "    self.embedding = nn.Embedding(self.output_vocab_len, self.input_dim)\n",
        "    self.dropout = nn.Dropout(self.drop_prob) \n",
        "    self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, batch_first=True)\n",
        "    self.classifier = nn.Linear(self.hidden_dim, self.output_vocab_len)\n",
        "\n",
        "  def forward(self, inputs, decoder_state_vector, decoder_context_vector):\n",
        "    # Embed input words\n",
        "    embedded = self.embedding(inputs).view(1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "    embedded = embedded.unsqueeze(0)\n",
        "    \n",
        "    output, hidden = self.lstm(embedded, (decoder_state_vector, \n",
        "                                          decoder_context_vector))\n",
        "\n",
        "    # Pass LSTM outputs through a Linear layer acting as a classifier\n",
        "    output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
        "\n",
        "    return output, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "syV2C9IY_WN2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train our model and save the trained model to the \"model\" directory."
      ],
      "metadata": {
        "id": "ufgTe0by6khT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 100\n",
        "hidden_dim = 256\n",
        "\n",
        "encoder = EncoderLSTM(len(en_words), input_dim, hidden_dim)\n",
        "decoder = DecoderLSTM(input_dim, hidden_dim, len(de_words))\n",
        " \n",
        "lr = 0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
        "\n",
        "EPOCHS = 10\n",
        "teacher_forcing_prob = 0.5\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "tk0 = range(1,EPOCHS+1)\n",
        "for epoch in tk0:\n",
        "    avg_loss = 0.\n",
        "    tk1 = enumerate(en_inputs)\n",
        "\n",
        "    for i, sentence in tk1:\n",
        "\n",
        "        loss = 0.\n",
        "\n",
        "        #initialise encoder state vector and cell state vector\n",
        "        h = encoder.init_hidden()\n",
        "        encoder_state_vector = h[0]\n",
        "        encoder_cell_vector = h[0]\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        inp = torch.tensor(sentence).unsqueeze(0)\n",
        "\n",
        "        #print('inp: ', epoch, inp)\n",
        "        if (i % 100) == 0:\n",
        "          print('inp: ', i, epoch)\n",
        "        encoder_outputs, h = encoder(inp, encoder_state_vector, encoder_cell_vector)\n",
        "        \n",
        "        #First decoder input will be the SOS token\n",
        "        decoder_input = torch.tensor([en_w2i['_SOS']])\n",
        "        #First decoder hidden state will be last encoder hidden state\n",
        "        decoder_hidden = h\n",
        "\n",
        "        output = []\n",
        "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
        "\n",
        "        for ii in range(len(de_inputs[i])):\n",
        "          decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden[0], decoder_hidden[1])\n",
        "\n",
        "          # Get the index value of the word with the highest score from the decoder output\n",
        "          top_value, top_index = decoder_output.topk(1)\n",
        "          if teacher_forcing:\n",
        "            decoder_input = torch.tensor([de_inputs[i][ii]])\n",
        "          else:\n",
        "            decoder_input = torch.tensor([top_index.item()])\n",
        "            \n",
        "          output.append(top_index.item())\n",
        "          # Calculate the loss of the prediction against the actual word\n",
        "          loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([de_inputs[i][ii]]))\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        avg_loss += loss.item()/len(en_inputs)\n",
        "    print(avg_loss)\n",
        "\n",
        "# Save model after every epoch (Optional)\n",
        "torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},root_path+\"model/model_enc_dec.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qqttxnJ2_qBS",
        "outputId": "c26f726e-23bd-4483-d16e-e9f3019841a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp:  0 1\n",
            "inp:  100 1\n",
            "inp:  200 1\n",
            "inp:  300 1\n",
            "inp:  400 1\n",
            "inp:  500 1\n",
            "inp:  600 1\n",
            "inp:  700 1\n",
            "inp:  800 1\n",
            "inp:  900 1\n",
            "inp:  1000 1\n",
            "inp:  1100 1\n",
            "inp:  1200 1\n",
            "inp:  1300 1\n",
            "inp:  1400 1\n",
            "inp:  1500 1\n",
            "inp:  1600 1\n",
            "inp:  1700 1\n",
            "inp:  1800 1\n",
            "inp:  1900 1\n",
            "inp:  2000 1\n",
            "inp:  2100 1\n",
            "inp:  2200 1\n",
            "inp:  2300 1\n",
            "inp:  2400 1\n",
            "inp:  2500 1\n",
            "inp:  2600 1\n",
            "inp:  2700 1\n",
            "inp:  2800 1\n",
            "inp:  2900 1\n",
            "inp:  3000 1\n",
            "inp:  3100 1\n",
            "inp:  3200 1\n",
            "inp:  3300 1\n",
            "inp:  3400 1\n",
            "31.72295134307297\n",
            "inp:  0 2\n",
            "inp:  100 2\n",
            "inp:  200 2\n",
            "inp:  300 2\n",
            "inp:  400 2\n",
            "inp:  500 2\n",
            "inp:  600 2\n",
            "inp:  700 2\n",
            "inp:  800 2\n",
            "inp:  900 2\n",
            "inp:  1000 2\n",
            "inp:  1100 2\n",
            "inp:  1200 2\n",
            "inp:  1300 2\n",
            "inp:  1400 2\n",
            "inp:  1500 2\n",
            "inp:  1600 2\n",
            "inp:  1700 2\n",
            "inp:  1800 2\n",
            "inp:  1900 2\n",
            "inp:  2000 2\n",
            "inp:  2100 2\n",
            "inp:  2200 2\n",
            "inp:  2300 2\n",
            "inp:  2400 2\n",
            "inp:  2500 2\n",
            "inp:  2600 2\n",
            "inp:  2700 2\n",
            "inp:  2800 2\n",
            "inp:  2900 2\n",
            "inp:  3000 2\n",
            "inp:  3100 2\n",
            "inp:  3200 2\n",
            "inp:  3300 2\n",
            "inp:  3400 2\n",
            "26.391889648460893\n",
            "inp:  0 3\n",
            "inp:  100 3\n",
            "inp:  200 3\n",
            "inp:  300 3\n",
            "inp:  400 3\n",
            "inp:  500 3\n",
            "inp:  600 3\n",
            "inp:  700 3\n",
            "inp:  800 3\n",
            "inp:  900 3\n",
            "inp:  1000 3\n",
            "inp:  1100 3\n",
            "inp:  1200 3\n",
            "inp:  1300 3\n",
            "inp:  1400 3\n",
            "inp:  1500 3\n",
            "inp:  1600 3\n",
            "inp:  1700 3\n",
            "inp:  1800 3\n",
            "inp:  1900 3\n",
            "inp:  2000 3\n",
            "inp:  2100 3\n",
            "inp:  2200 3\n",
            "inp:  2300 3\n",
            "inp:  2400 3\n",
            "inp:  2500 3\n",
            "inp:  2600 3\n",
            "inp:  2700 3\n",
            "inp:  2800 3\n",
            "inp:  2900 3\n",
            "inp:  3000 3\n",
            "inp:  3100 3\n",
            "inp:  3200 3\n",
            "inp:  3300 3\n",
            "inp:  3400 3\n",
            "24.199119108904867\n",
            "inp:  0 4\n",
            "inp:  100 4\n",
            "inp:  200 4\n",
            "inp:  300 4\n",
            "inp:  400 4\n",
            "inp:  500 4\n",
            "inp:  600 4\n",
            "inp:  700 4\n",
            "inp:  800 4\n",
            "inp:  900 4\n",
            "inp:  1000 4\n",
            "inp:  1100 4\n",
            "inp:  1200 4\n",
            "inp:  1300 4\n",
            "inp:  1400 4\n",
            "inp:  1500 4\n",
            "inp:  1600 4\n",
            "inp:  1700 4\n",
            "inp:  1800 4\n",
            "inp:  1900 4\n",
            "inp:  2000 4\n",
            "inp:  2100 4\n",
            "inp:  2200 4\n",
            "inp:  2300 4\n",
            "inp:  2400 4\n",
            "inp:  2500 4\n",
            "inp:  2600 4\n",
            "inp:  2700 4\n",
            "inp:  2800 4\n",
            "inp:  2900 4\n",
            "inp:  3000 4\n",
            "inp:  3100 4\n",
            "inp:  3200 4\n",
            "inp:  3300 4\n",
            "inp:  3400 4\n",
            "22.50368644615881\n",
            "inp:  0 5\n",
            "inp:  100 5\n",
            "inp:  200 5\n",
            "inp:  300 5\n",
            "inp:  400 5\n",
            "inp:  500 5\n",
            "inp:  600 5\n",
            "inp:  700 5\n",
            "inp:  800 5\n",
            "inp:  900 5\n",
            "inp:  1000 5\n",
            "inp:  1100 5\n",
            "inp:  1200 5\n",
            "inp:  1300 5\n",
            "inp:  1400 5\n",
            "inp:  1500 5\n",
            "inp:  1600 5\n",
            "inp:  1700 5\n",
            "inp:  1800 5\n",
            "inp:  1900 5\n",
            "inp:  2000 5\n",
            "inp:  2100 5\n",
            "inp:  2200 5\n",
            "inp:  2300 5\n",
            "inp:  2400 5\n",
            "inp:  2500 5\n",
            "inp:  2600 5\n",
            "inp:  2700 5\n",
            "inp:  2800 5\n",
            "inp:  2900 5\n",
            "inp:  3000 5\n",
            "inp:  3100 5\n",
            "inp:  3200 5\n",
            "inp:  3300 5\n",
            "inp:  3400 5\n",
            "21.19593310111852\n",
            "inp:  0 6\n",
            "inp:  100 6\n",
            "inp:  200 6\n",
            "inp:  300 6\n",
            "inp:  400 6\n",
            "inp:  500 6\n",
            "inp:  600 6\n",
            "inp:  700 6\n",
            "inp:  800 6\n",
            "inp:  900 6\n",
            "inp:  1000 6\n",
            "inp:  1100 6\n",
            "inp:  1200 6\n",
            "inp:  1300 6\n",
            "inp:  1400 6\n",
            "inp:  1500 6\n",
            "inp:  1600 6\n",
            "inp:  1700 6\n",
            "inp:  1800 6\n",
            "inp:  1900 6\n",
            "inp:  2000 6\n",
            "inp:  2100 6\n",
            "inp:  2200 6\n",
            "inp:  2300 6\n",
            "inp:  2400 6\n",
            "inp:  2500 6\n",
            "inp:  2600 6\n",
            "inp:  2700 6\n",
            "inp:  2800 6\n",
            "inp:  2900 6\n",
            "inp:  3000 6\n",
            "inp:  3100 6\n",
            "inp:  3200 6\n",
            "inp:  3300 6\n",
            "inp:  3400 6\n",
            "19.864574568355923\n",
            "inp:  0 7\n",
            "inp:  100 7\n",
            "inp:  200 7\n",
            "inp:  300 7\n",
            "inp:  400 7\n",
            "inp:  500 7\n",
            "inp:  600 7\n",
            "inp:  700 7\n",
            "inp:  800 7\n",
            "inp:  900 7\n",
            "inp:  1000 7\n",
            "inp:  1100 7\n",
            "inp:  1200 7\n",
            "inp:  1300 7\n",
            "inp:  1400 7\n",
            "inp:  1500 7\n",
            "inp:  1600 7\n",
            "inp:  1700 7\n",
            "inp:  1800 7\n",
            "inp:  1900 7\n",
            "inp:  2000 7\n",
            "inp:  2100 7\n",
            "inp:  2200 7\n",
            "inp:  2300 7\n",
            "inp:  2400 7\n",
            "inp:  2500 7\n",
            "inp:  2600 7\n",
            "inp:  2700 7\n",
            "inp:  2800 7\n",
            "inp:  2900 7\n",
            "inp:  3000 7\n",
            "inp:  3100 7\n",
            "inp:  3200 7\n",
            "inp:  3300 7\n",
            "inp:  3400 7\n",
            "18.871908455984787\n",
            "inp:  0 8\n",
            "inp:  100 8\n",
            "inp:  200 8\n",
            "inp:  300 8\n",
            "inp:  400 8\n",
            "inp:  500 8\n",
            "inp:  600 8\n",
            "inp:  700 8\n",
            "inp:  800 8\n",
            "inp:  900 8\n",
            "inp:  1000 8\n",
            "inp:  1100 8\n",
            "inp:  1200 8\n",
            "inp:  1300 8\n",
            "inp:  1400 8\n",
            "inp:  1500 8\n",
            "inp:  1600 8\n",
            "inp:  1700 8\n",
            "inp:  1800 8\n",
            "inp:  1900 8\n",
            "inp:  2000 8\n",
            "inp:  2100 8\n",
            "inp:  2200 8\n",
            "inp:  2300 8\n",
            "inp:  2400 8\n",
            "inp:  2500 8\n",
            "inp:  2600 8\n",
            "inp:  2700 8\n",
            "inp:  2800 8\n",
            "inp:  2900 8\n",
            "inp:  3000 8\n",
            "inp:  3100 8\n",
            "inp:  3200 8\n",
            "inp:  3300 8\n",
            "inp:  3400 8\n",
            "17.810046842182405\n",
            "inp:  0 9\n",
            "inp:  100 9\n",
            "inp:  200 9\n",
            "inp:  300 9\n",
            "inp:  400 9\n",
            "inp:  500 9\n",
            "inp:  600 9\n",
            "inp:  700 9\n",
            "inp:  800 9\n",
            "inp:  900 9\n",
            "inp:  1000 9\n",
            "inp:  1100 9\n",
            "inp:  1200 9\n",
            "inp:  1300 9\n",
            "inp:  1400 9\n",
            "inp:  1500 9\n",
            "inp:  1600 9\n",
            "inp:  1700 9\n",
            "inp:  1800 9\n",
            "inp:  1900 9\n",
            "inp:  2000 9\n",
            "inp:  2100 9\n",
            "inp:  2200 9\n",
            "inp:  2300 9\n",
            "inp:  2400 9\n",
            "inp:  2500 9\n",
            "inp:  2600 9\n",
            "inp:  2700 9\n",
            "inp:  2800 9\n",
            "inp:  2900 9\n",
            "inp:  3000 9\n",
            "inp:  3100 9\n",
            "inp:  3200 9\n",
            "inp:  3300 9\n",
            "inp:  3400 9\n",
            "16.977326881313033\n",
            "inp:  0 10\n",
            "inp:  100 10\n",
            "inp:  200 10\n",
            "inp:  300 10\n",
            "inp:  400 10\n",
            "inp:  500 10\n",
            "inp:  600 10\n",
            "inp:  700 10\n",
            "inp:  800 10\n",
            "inp:  900 10\n",
            "inp:  1000 10\n",
            "inp:  1100 10\n",
            "inp:  1200 10\n",
            "inp:  1300 10\n",
            "inp:  1400 10\n",
            "inp:  1500 10\n",
            "inp:  1600 10\n",
            "inp:  1700 10\n",
            "inp:  1800 10\n",
            "inp:  1900 10\n",
            "inp:  2000 10\n",
            "inp:  2100 10\n",
            "inp:  2200 10\n",
            "inp:  2300 10\n",
            "inp:  2400 10\n",
            "inp:  2500 10\n",
            "inp:  2600 10\n",
            "inp:  2700 10\n",
            "inp:  2800 10\n",
            "inp:  2900 10\n",
            "inp:  3000 10\n",
            "inp:  3100 10\n",
            "inp:  3200 10\n",
            "inp:  3300 10\n",
            "inp:  3400 10\n",
            "16.358729444080584\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-46143924d6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Save model after every epoch (Optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"encoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"decoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"e_optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"d_optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"model/model_enc_dec.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'root_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the pretrained model to check translation for some random sentences in the corpus."
      ],
      "metadata": {
        "id": "C8rbwSCMKOx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint = torch.load(root_path+\"model/model_enc_dec.pt\")\n",
        "\n",
        "#encoder.load_state_dict(checkpoint['encoder'])\n",
        "#decoder.load_state_dict(checkpoint['decoder'])\n",
        "#encoder_optimizer.load_state_dict(checkpoint['e_optimizer'])\n",
        "#decoder_optimizer.load_state_dict(checkpoint['d_optimizer'])\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# get some random numbers to choose random sentences\n",
        "rand_integers = [random.randint(0, len(en_inputs)) for i in range(1, 20)]\n",
        "\n",
        "for i in rand_integers:\n",
        "  h = encoder.init_hidden()\n",
        "  inp = torch.tensor(en_inputs[i]).unsqueeze(0)\n",
        "  encoder_outputs, h = encoder(inp, h[0], h[1])\n",
        "   \n",
        "  decoder_input = torch.tensor([en_w2i['_SOS']])\n",
        "  decoder_hidden = h\n",
        "  output = []\n",
        "  attentions = []\n",
        "  while True:\n",
        "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden[0], decoder_hidden[1])\n",
        "    _, top_index = decoder_output.topk(1)\n",
        "    decoder_input = torch.tensor([top_index.item()])\n",
        "    # If the decoder output is the End Of Sentence token, stop decoding process\n",
        "    if top_index.item() == de_w2i[\"_EOS\"]:\n",
        "      break\n",
        "    output.append(top_index.item())\n",
        "  \n",
        "  print(\"English: \"+ \" \".join([en_i2w[x] for x in en_inputs[i]]))\n",
        "  print(\"Predicted: \" + \" \".join([de_i2w[x] for x in output]))\n",
        "  print(\"Actual: \" + \" \".join([de_i2w[x] for x in de_inputs[i]]))\n",
        "  print()\n",
        "   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ufbdIyUwzE-",
        "outputId": "a33af33d-9e6b-43a0-cb33-44e864653fa4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: what exception to the rules of vowel harmony do compound words have ? _EOS\n",
            "Predicted: the\n",
            "Actual: in compound words , the vowels need not harmonize between the constituent words of the compound . _EOS\n",
            "\n",
            "English: do the different species of zebras interbreed ? _EOS\n",
            "Predicted: no\n",
            "Actual: no _EOS\n",
            "\n",
            "English: what is the most common romanization standard for standard mandarin today ? _EOS\n",
            "Predicted: the\n",
            "Actual: hanyu pinyin _EOS\n",
            "\n",
            "English: has swahili no diphthongs ? _EOS\n",
            "Predicted: no\n",
            "Actual: no _EOS\n",
            "\n",
            "English: what is the name of a university ( or similar institution for imparting higher education ) in beijing ? _EOS\n",
            "Predicted: the\n",
            "Actual: tsinghua university _EOS\n",
            "\n",
            "English: during his lifetime , did pollock enjoy considerable fame and notoriety ? _EOS\n",
            "Predicted: yes\n",
            "Actual: yes . _EOS\n",
            "\n",
            "English: was it likely that the xylophone reached europe during the crusades ? _EOS\n",
            "Predicted: yes\n",
            "Actual: yes . _EOS\n",
            "\n",
            "English: when was james monroe appointed to secretary of war ? _EOS\n",
            "Predicted: in\n",
            "Actual: 1814 _EOS\n",
            "\n",
            "English: are there also large populations of german ancestry in mexico ? _EOS\n",
            "Predicted: yes\n",
            "Actual: yes _EOS\n",
            "\n",
            "English: do male giraffes have larger horns than female giraffes ? _EOS\n",
            "Predicted: yes\n",
            "Actual: yes _EOS\n",
            "\n",
            "English: what countries border egypt ? _EOS\n",
            "Predicted: piccolo trumpets\n",
            "Actual: libya , sudan , the gaza strip and israel . _EOS\n",
            "\n",
            "English: when do wolves molt ? _EOS\n",
            "Predicted: in between june october\n",
            "Actual: late spring or early summer _EOS\n",
            "\n",
            "English: do the ants eat plants , meats , or both ? _EOS\n",
            "Predicted: no\n",
            "Actual: both _EOS\n",
            "\n",
            "English: are tigers solitary animals ? _EOS\n",
            "Predicted: yes\n",
            "Actual: yes . _EOS\n",
            "\n",
            "English: what are the three sections of a beetle ? _EOS\n",
            "Predicted: the\n",
            "Actual: the head , the thorax , and the abdomen _EOS\n",
            "\n",
            "English: why do kangaroos have a wide bite ? _EOS\n",
            "Predicted: because it was the indefinite\n",
            "Actual: the two sides of the lower jaw are not joined together and the lower incisors are farther apart . _EOS\n",
            "\n",
            "English: where do sea otters live ? _EOS\n",
            "Predicted: the was the 20th century .\n",
            "Actual: sea otters ( enhydra lutris ) live along the pacific coast of north america . _EOS\n",
            "\n",
            "English: is jakarta a city _EOS\n",
            "Predicted: yes\n",
            "Actual: yes _EOS\n",
            "\n",
            "English: for how many years did alessandro volta live ? _EOS\n",
            "Predicted: three\n",
            "Actual: 53 _EOS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_inputs)"
      ],
      "metadata": {
        "id": "_Z0I_QmPSUYW",
        "outputId": "211578d1-b964-4944-894c-63347d577745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3422"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_inputs[25]"
      ],
      "metadata": {
        "id": "wD43AL5ISd11",
        "outputId": "644092c6-45a6-47f1-d923-2002123eefc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46, 401, 10, 93, 44, 8, 3, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "993aJ6OESqxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}